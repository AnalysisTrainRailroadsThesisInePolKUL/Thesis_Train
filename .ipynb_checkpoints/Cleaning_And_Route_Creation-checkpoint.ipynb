{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import the required packages.'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Display all output results of a Jupyter cell.'''\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ensure that the output results of extensive output results are not truncated.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ensure that the output results of extensive output results are not truncated.'''\n",
    "#pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Change the width of the Notebook to see the output on the screen'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Change the width of the Notebook to see the output on the screen'''\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Register the GitHub link or the file relative location'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Register the GitHub link or the file relative location'''\n",
    "#the Github link\n",
    "#repository_loc = \"https://raw.githubusercontent.com/polkuleuven/Thesis_Train/main\"\n",
    "#the local link\n",
    "repository_loc = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get the other folder locations'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Get the other folder locations'''\n",
    "belgian_GTFS_loc = repository_loc + '/gtfs_train_Belgium_1503/'\n",
    "dutch_GTFS_loc = repository_loc + '/gtfs_train_Netherlands_1503/'\n",
    "swiss_GTFS_loc = repository_loc + '/gtfs_train_Switzerland_1503/'\n",
    "\n",
    "stops_series_loc = repository_loc + '/country_stops_series/'\n",
    "stops_cleaned_loc = repository_loc + '/stops_cleaned/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Import all the DataFrames that are common for the three train networks'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Import all the DataFrames that are common for the three train networks'''\n",
    "\n",
    "def common_imports(datalink):\n",
    "    #To import the agency dataset that contains limited information about the railway agency.\n",
    "    agency = pd.read_csv(datalink + \"agency.txt\", sep=\",\")\n",
    "    #To import the calendar_dates dataset that gives for each service_id all the exact dates when that service_id is valid.\n",
    "    calendar_dates = pd.read_csv(datalink + \"calendar_dates.txt\", sep=\",\")\n",
    "    #To import the routes dataset that provides the id, the name and the type of vehicle used for all railway routes.\n",
    "    routes = pd.read_csv(datalink + \"routes.txt\", sep=\",\")\n",
    "    #To import the stops dataset that contains information about the ids, the names and the geographical coordinates of the railway stations.\n",
    "    stops = pd.read_csv(datalink + \"stops.txt\", sep=\",\")\n",
    "    #To import the transfers dataset that gives the minimum transfer time to switch routes at each railway station.\n",
    "    transfers = pd.read_csv(datalink + \"transfers.txt\", sep=\",\")\n",
    "    #To import the trips dataset that gives for all routes an overview of the trips and the headsigns of these trips belonging to the railway route.\n",
    "    #The service_id is an indication of all the dates this trip is valid (consultable in the calendar_dates dataset).\n",
    "    trips = pd.read_csv(datalink + \"trips.txt\", sep=\",\")\n",
    "    return agency, calendar_dates, routes, stops, transfers, trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acutal imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belgium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply common_import()'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply common_import()'''\n",
    "agency_Belgium, calendar_dates_Belgium, routes_Belgium, stops_Belgium, transfers_Belgium, trips_Belgium = common_imports(belgian_GTFS_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Import other DataFrames'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Import other DataFrames'''\n",
    "#To import the translations dataset that provides the French-, Dutch-, German- and English-language translations of the Belgian railway stations.\n",
    "translations_Belgium = pd.read_csv(belgian_GTFS_loc + \"translations.txt\", sep=\",\")\n",
    "#To import the stop_times dataset that gives for all trips an overview of the ids of the stations served and the sequence in which these stations are served. \n",
    "#In addition, for all the trips the arrival and departure times at the stations served are given.\n",
    "stop_times_Belgium = pd.read_csv(belgian_GTFS_loc + \"stop_times.txt\", sep=\",\")\n",
    "#To import the calendar dataset that gives the first and last date of all data observations.\n",
    "calendar_Belgium = pd.read_csv(belgian_GTFS_loc + \"calendar.txt\", sep=\",\")\n",
    "#To import the stop_time_overrides dataset \n",
    "stop_time_overrides_Belgium = pd.read_csv(belgian_GTFS_loc + \"stop_time_overrides.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply common_import()'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply common_import()'''\n",
    "agency_Netherlands, calendar_dates_Netherlands, routes_Netherlands, stops_Netherlands, transfers_not_cleaned_Netherlands, trips_Netherlands = common_imports(dutch_GTFS_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Import other DataFrames'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Import other DataFrames'''\n",
    "#To import the feed_info dataset that contains limited information about the Dutch NS railway feed.\n",
    "feed_info_Netherlands = pd.read_csv(dutch_GTFS_loc + \"feed_info.txt\", sep=\",\")\n",
    "#To import the stop_times dataset that gives for all trips an overview of the ids of the stations served and the sequence in which these stations are served. \n",
    "#In addition, for all the trips the arrival and departure times at the stations served are given.\n",
    "stop_times_range = [*range(2, 19)]\n",
    "stop_times_Netherlands = pd.read_csv(dutch_GTFS_loc + \"stop_times-1.csv\", sep=\",\")\n",
    "for index in stop_times_range:\n",
    "    stop_times_Netherlands = pd.concat([stop_times_Netherlands, pd.read_csv(dutch_GTFS_loc + \"stop_times-\" + str(index)+ \".csv\", sep=\",\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply common_import()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply common_import()'''\n",
    "agency_Switzerland, calendar_dates_Switzerland, routes_Switzerland, stops_Switzerland, transfers_not_cleaned_Switzerland, trips_Switzerland = common_imports(swiss_GTFS_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Import other DataFrames'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pol/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "'''Import other DataFrames'''\n",
    "#To import the feed_info dataset that contains limited information about the Swiss SBB railway feed.\n",
    "feed_info_Switzerland = pd.read_csv(swiss_GTFS_loc + \"feed_info.txt\", sep=\",\")\n",
    "#To import the stop_times dataset that gives for all trips an overview of the ids of the stations served and the sequence in which these stations are served. \n",
    "#In addition, for all the trips the arrival and departure times at the stations served are given.\n",
    "stop_times_Switzerland = pd.read_csv(swiss_GTFS_loc + \"stop_times.txt\", sep=\",\")\n",
    "#To import the calendar dataset that gives the first and last date of all data observations.\n",
    "calendar_Switzerland = pd.read_csv(swiss_GTFS_loc + \"calendar.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of the railway data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the calendar_dates DataFrame'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Clean the calendar_dates DataFrame'''\n",
    "\n",
    "def clean_calendar_dates(calendar_dates):\n",
    "    #To filter the dates from the selected begin to the end date\n",
    "    begin_date = 20210314\n",
    "    end_date = 20210713\n",
    "    calendar_dates_cleaned = calendar_dates.copy()\n",
    "    calendar_dates_cleaned = calendar_dates_cleaned.drop(calendar_dates_cleaned[(calendar_dates_cleaned['date'] > end_date) | (calendar_dates_cleaned['date'] < begin_date)].index)\n",
    "    return calendar_dates_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Add the country to the stops DataFrame and returns the country filtered DataFrame of stops and the serie of those stops'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Add the country to the stops DataFrame and returns the country filtered DataFrame of stops and the serie of those stops'''\n",
    "\n",
    "def country_information(stops, country_name, stops_cleaned_loc, stops_series_loc):\n",
    "    #To initialize the Nominatim API to get the location from the input string \n",
    "    geolocator = Nominatim(user_agent=\"application\")\n",
    "    reverse = RateLimiter(geolocator.reverse, min_delay_seconds=0.2)\n",
    "\n",
    "    #To get the location with the geolocator.reverse() function and to extract the country from the location instance\n",
    "    country_list = []\n",
    "    for index, row in stops.iterrows():\n",
    "        latitude = row['stop_lat']\n",
    "        longitude = row['stop_lon']\n",
    "        # To assign the latitude and longitude into a geolocator.reverse() method\n",
    "        location = reverse((latitude, longitude), language='en', exactly_one=True)\n",
    "        # To get the country from the given list and parsed into a dictionary with raw function()\n",
    "        address = location.raw['address']\n",
    "        country = address.get('country', '')\n",
    "        country_list.append(country)\n",
    "\n",
    "    #To add the values of country_list as a new attribute country \n",
    "    stops.loc[:,'country'] = country_list\n",
    "\n",
    "    #To calculate the total number of Belgian stations in the stops dataset\n",
    "    country_stops = stops[stops['country'] == country_name]\n",
    "    country_stops_series = stops.loc[stops['country'] == country_name, 'stop_name']\n",
    "    \n",
    "    stops.to_csv(f'{stops_cleaned_loc}stops_cleaned_{country_name}.csv')\n",
    "    country_stops_series.to_csv(f'{stops_series_loc}stops_{country_name}_series.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remove the accents from a string'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Remove the accents from a string'''\n",
    "\n",
    "def remove_accents(text):\n",
    "    import unicodedata\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError:\n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acutal cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belgium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the routes_Belgium df'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Clean the routes_Belgium df'''\n",
    "allowed_route_type = {'IC', 'L', 'P', 'ICT', 'IZY'}\n",
    "routes_cleaned_Belgium = routes_Belgium[(routes_Belgium['route_short_name'].isin(allowed_route_type)) | (routes_Belgium['route_short_name'].str.startswith('S'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply clean_calendar_dates()'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply clean_calendar_dates()'''\n",
    "calendar_dates_cleaned_Belgium = clean_calendar_dates(calendar_dates_Belgium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the stops_Belgium df.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pol/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "'''Clean the stops_Belgium df.''' \n",
    "#To eliminate the stop_ids in the stops dataset that contain an underscore or that start with a character 'S'. \n",
    "stops_cleaned_Belgium = stops_Belgium[(~stops_Belgium['stop_id'].str.contains('_')) & (~stops_Belgium['stop_id'].str.contains('S'))]\n",
    "\n",
    "#To modify the object datatype of the stop_id column to the NumPy int64 datatype\n",
    "stops_cleaned_Belgium.loc[:,'stop_id'] = stops_cleaned_Belgium.loc[:,'stop_id'].astype(np.int64)\n",
    "\n",
    "#To remove the accents from the stop_name and to change to uppercase\n",
    "stops_cleaned_Belgium.loc[:,'stop_name'] = stops_cleaned_Belgium.loc[:,'stop_name'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "stops_cleaned_Belgium.loc[:,'stop_name'] = stops_cleaned_Belgium.loc[:,'stop_name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply country_information() and take the DataFrames from the files'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply country_information() and take the DataFrames from the files'''\n",
    "country_name = 'Belgium'\n",
    "#country_information(stops_cleaned_Belgium, country_name, stops_cleaned_loc, stops_series_loc)\n",
    "stops_cleaned_Belgium = pd.read_csv(f\"{stops_cleaned_loc}stops_cleaned_{country_name}.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the routes_Netherlands DataFrame'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>agency_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>route_desc</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_color</th>\n",
       "      <th>route_text_color</th>\n",
       "      <th>route_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>145</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>17803</td>\n",
       "      <td>IFF:NS</td>\n",
       "      <td>Sprinter</td>\n",
       "      <td>Nachtnettrein Utrecht Centraal &lt;-&gt; Rotterdam C...</td>\n",
       "      <td>nan</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       route_id agency_id route_short_name  \\\n",
       "count       145       145              145   \n",
       "unique      145        11               15   \n",
       "top       17803    IFF:NS         Sprinter   \n",
       "freq          1        87               47   \n",
       "\n",
       "                                          route_long_name route_desc  \\\n",
       "count                                                 145        145   \n",
       "unique                                                144          1   \n",
       "top     Nachtnettrein Utrecht Centraal <-> Rotterdam C...        nan   \n",
       "freq                                                    2        145   \n",
       "\n",
       "       route_type route_color route_text_color route_url  \n",
       "count         145         145              145       145  \n",
       "unique          1           1                1         1  \n",
       "top             2         nan              nan       nan  \n",
       "freq          145         145              145       145  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Clean the routes_Netherlands DataFrame'''\n",
    "#To keep the train routes\n",
    "routes_cleaned_Netherlands = routes_Netherlands[routes_Netherlands['route_type'] == 2]\n",
    "routes_cleaned_Netherlands = routes_cleaned_Netherlands.astype(str)\n",
    "routes_cleaned_Netherlands.describe(include=['object'])\n",
    "\n",
    "#To change the route_id object datatype to a NumPy int64 datatype\n",
    "routes_cleaned_Netherlands.loc[:,'route_id'] = routes_cleaned_Netherlands.loc[:,'route_id'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply clean_calendar_dates()'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply clean_calendar_dates()'''\n",
    "calendar_dates_cleaned_Netherlands = clean_calendar_dates(calendar_dates_Netherlands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the stops DataFrame'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pol/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "'''Clean the stops DataFrame'''\n",
    "#To take from the stops_initial_Netherlands df all stop_ids that contain a 'stoparea:' to get the correct stop coordinates\n",
    "stops_cleaned_Netherlands = stops_Netherlands[stops_Netherlands['stop_id'].str.contains('stoparea:')]\n",
    "\n",
    "#To remove the accents from the accented characters and to convert the remaining characters to uppercase characters\n",
    "stops_cleaned_Netherlands.loc[:,'stop_name'] = stops_cleaned_Netherlands.loc[:,'stop_name'].apply(remove_accents)\n",
    "stops_cleaned_Netherlands.loc[:,'stop_name'] = stops_cleaned_Netherlands.loc[:,'stop_name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply country_information() and take the DataFrames from the files'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply country_information() and take the DataFrames from the files'''\n",
    "country_name = 'Netherlands'\n",
    "#country_information(stops_cleaned_Netherlands, country_name, stops_cleaned_loc, stops_series_loc)\n",
    "stops_cleaned_Netherlands = pd.read_csv(f\"{stops_cleaned_loc}stops_cleaned_{country_name}.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the stop_times df'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Clean the stop_times df'''\n",
    "stop_times_cleaned_Netherlands = stop_times_Netherlands.copy()\n",
    "stop_times_cleaned_Netherlands.loc[:,'stop_id'] = stop_times_cleaned_Netherlands.stop_id.apply(str)\n",
    "stop_times_cleaned_Netherlands = pd.merge(stop_times_cleaned_Netherlands, stops_Netherlands[['stop_id', 'stop_name']], on='stop_id')\n",
    "stop_times_cleaned_Netherlands.loc[:,'stop_name'] = stop_times_cleaned_Netherlands.loc[:,'stop_name'].apply(remove_accents)\n",
    "stop_times_cleaned_Netherlands.loc[:,'stop_name'] = stop_times_cleaned_Netherlands.loc[:,'stop_name'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the routes_Switzerland DataFrame'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Clean the routes_Switzerland DataFrame'''\n",
    "#To keep the train routes\n",
    "routes_cleaned_Switzerland = routes_Switzerland[routes_Switzerland['route_type'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply clean_calendar_dates()'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply clean_calendar_dates()'''\n",
    "calendar_dates_cleaned_Switzerland = clean_calendar_dates(calendar_dates_Switzerland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the stop_times_Switzerland DataFrame'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Clean the stop_times_Switzerland DataFrame'''\n",
    "# To remove the superfluous characters of the stop_id (platform codes)\n",
    "stop_times_cleaned_Switzerland = stop_times_Switzerland.copy()\n",
    "stop_times_cleaned_Switzerland_column = stop_times_cleaned_Switzerland['stop_id'].str.split(':').str[0]\n",
    "stop_times_cleaned_Switzerland.loc[:,'stop_id'] = stop_times_cleaned_Switzerland_column\n",
    "\n",
    "# To make the stop_ids numerical \n",
    "stop_times_cleaned_Switzerland.loc[:,'stop_id'] = stop_times_cleaned_Switzerland.loc[:,'stop_id'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the stops_Switzerland DataFrame'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Clean the stops_Switzerland DataFrame'''\n",
    "#To remove the superfluous characters (platform codes)\n",
    "stops_cleaned_Switzerland_column = stops_Switzerland['stop_id'].str.split(':').str[0]\n",
    "stops_cleaned_Switzerland = stops_Switzerland.copy()\n",
    "stops_cleaned_Switzerland.loc[:,'stop_id'] = stops_cleaned_Switzerland_column\n",
    "\n",
    "#To make the stop_ids numerical and to remove the duplicate stop_ids\n",
    "stops_cleaned_Switzerland = stops_cleaned_Switzerland[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']]\n",
    "stops_cleaned_Switzerland.loc[:,'stop_id'] = stops_cleaned_Switzerland.loc[:,'stop_id'].astype(np.int64)\n",
    "stops_cleaned_Switzerland = stops_cleaned_Switzerland.drop_duplicates()\n",
    "\n",
    "#To remove the accents from the stop_name and to change to uppercase\n",
    "stops_cleaned_Switzerland.loc[:,'stop_name'] = stops_cleaned_Switzerland.loc[:,'stop_name'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "stops_cleaned_Switzerland.loc[:,'stop_name'] = stops_cleaned_Switzerland.loc[:,'stop_name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply country_information() and take the DataFrames from the files'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply country_information() and take the DataFrames from the files'''\n",
    "country_name = 'Switzerland'\n",
    "#country_information(stops_cleaned_Switzerland, country_name, stops_cleaned_loc, stops_series_loc)\n",
    "stops_cleaned_Switzerland = pd.read_csv(f\"{stops_cleaned_loc}stops_cleaned_{country_name}.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Merge the DataFrames'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Merge the DataFrames'''\n",
    "\n",
    "def merge_df(stop_times, stops, routes, trips, calendar_dates, on_stop):\n",
    "    list_columns = ['stop_name', 'stop_lat', 'stop_lon', 'country']\n",
    "    if on_stop == 'stop_id':\n",
    "        list_columns.append('stop_id')\n",
    "    #To merge the stop_times df with the stops df on stop_id\n",
    "    stop_times_stops = pd.merge(stop_times, stops[list_columns], on= on_stop)\n",
    "\n",
    "    #To merge the trips df with the routes df on route_id\n",
    "    routes_trips = pd.merge(routes[['route_id']], trips, on='route_id')\n",
    "\n",
    "    #To merge the stop_times_stops df with the trips_routes df on trip_id\n",
    "    uncleaned_railway_system_information = pd.merge(routes_trips, stop_times_stops, on='trip_id')\n",
    "\n",
    "    #To take only the service_ids present in both the routes_trips_stop_times_stops df and the calendar_dates df into account\n",
    "    calendar_dates_unique = calendar_dates['service_id'].unique()\n",
    "    railway_system_information = uncleaned_railway_system_information[(uncleaned_railway_system_information['service_id'].isin(calendar_dates_unique))]\n",
    "    \n",
    "    return railway_system_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belgium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Select all required fields'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Select all required fields'''\n",
    "agency_cleaned_Belgium = agency_Belgium[['agency_id', 'agency_name', 'agency_url', 'agency_timezone']]\n",
    "routes_cleaned_Belgium = routes_cleaned_Belgium[['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type']]\n",
    "trips_cleaned_Belgium = trips_Belgium[['trip_id', 'route_id', 'service_id', 'trip_headsign']]\n",
    "calendar_dates_cleaned_Belgium = calendar_dates_cleaned_Belgium[['service_id', 'date']]\n",
    "stops_cleaned_Belgium = stops_cleaned_Belgium[['stop_id', 'stop_name', 'stop_lat', 'stop_lon', 'country']]\n",
    "stop_times_cleaned_Belgium = stop_times_Belgium[['trip_id', 'stop_id', 'arrival_time', 'departure_time', 'stop_sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply merge_df()'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply merge_df()'''\n",
    "railway_system_information_Belgium = merge_df(stop_times_cleaned_Belgium, stops_cleaned_Belgium, routes_cleaned_Belgium, trips_cleaned_Belgium, calendar_dates_cleaned_Belgium, 'stop_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Select all required fields'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Select all required fields'''\n",
    "agency_cleaned_Netherlands = agency_Netherlands[['agency_id', 'agency_name', 'agency_url', 'agency_timezone']]\n",
    "routes_cleaned_Netherlands = routes_cleaned_Netherlands[['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type']]\n",
    "trips_cleaned_Netherlands = trips_Netherlands[['trip_id', 'route_id', 'service_id', 'trip_headsign']]\n",
    "calendar_dates_cleaned_Netherlands = calendar_dates_cleaned_Netherlands[['service_id', 'date']]\n",
    "stops_cleaned_Netherlands = stops_cleaned_Netherlands[['stop_name', 'stop_lat', 'stop_lon', 'country']]\n",
    "stop_times_cleaned_Netherlands = stop_times_cleaned_Netherlands[['trip_id', 'stop_name', 'arrival_time', 'departure_time', 'stop_sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply merge_df()'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply merge_df()'''\n",
    "railway_system_information_Netherlands = merge_df(stop_times_cleaned_Netherlands, stops_cleaned_Netherlands, routes_cleaned_Netherlands, trips_cleaned_Netherlands, calendar_dates_cleaned_Netherlands, 'stop_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Select all required fields'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Select all required fields'''\n",
    "agency_cleaned_Switzerland = agency_Switzerland[['agency_id', 'agency_name', 'agency_url', 'agency_timezone']]\n",
    "routes_cleaned_Switzerland = routes_cleaned_Switzerland[['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type']]\n",
    "trips_cleaned_Switzerland = trips_Switzerland[['trip_id', 'route_id', 'service_id', 'trip_headsign']]\n",
    "calendar_dates_cleaned_Switzerland = calendar_dates_cleaned_Switzerland[['service_id', 'date']]\n",
    "stops_cleaned_Switzerland = stops_cleaned_Switzerland[['stop_id', 'stop_name', 'stop_lat', 'stop_lon', 'country']]\n",
    "stop_times_cleaned_Switzerland = stop_times_cleaned_Switzerland[['trip_id', 'stop_id', 'arrival_time', 'departure_time', 'stop_sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apply merge_df()'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply merge_df()'''\n",
    "railway_system_information_Switzerland = merge_df(stop_times_cleaned_Switzerland, stops_cleaned_Switzerland, routes_cleaned_Switzerland, trips_cleaned_Switzerland, calendar_dates_cleaned_Switzerland, 'stop_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for the space-of-stops representation of the railway systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>88____:007::8885704:8885001:4:523:20210418</td>\n",
       "      <td>14</td>\n",
       "      <td>Tournai</td>\n",
       "      <td>8885001</td>\n",
       "      <td>05:23:00</td>\n",
       "      <td>05:23:00</td>\n",
       "      <td>4</td>\n",
       "      <td>TOURNAI</td>\n",
       "      <td>50.61313</td>\n",
       "      <td>3.396940</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>88____:007::8885704:8885001:4:523:20210418</td>\n",
       "      <td>14</td>\n",
       "      <td>Tournai</td>\n",
       "      <td>8885068</td>\n",
       "      <td>05:19:00</td>\n",
       "      <td>05:19:00</td>\n",
       "      <td>3</td>\n",
       "      <td>FROYENNES</td>\n",
       "      <td>50.62989</td>\n",
       "      <td>3.354835</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>88____:007::8885704:8885001:4:523:20210418</td>\n",
       "      <td>14</td>\n",
       "      <td>Tournai</td>\n",
       "      <td>8885753</td>\n",
       "      <td>05:12:00</td>\n",
       "      <td>05:12:00</td>\n",
       "      <td>2</td>\n",
       "      <td>HERSEAUX</td>\n",
       "      <td>50.71390</td>\n",
       "      <td>3.245961</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115</td>\n",
       "      <td>88____:007::8885704:8885001:4:523:20210418</td>\n",
       "      <td>14</td>\n",
       "      <td>Tournai</td>\n",
       "      <td>8885704</td>\n",
       "      <td>05:07:00</td>\n",
       "      <td>05:07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>MOUSCRON</td>\n",
       "      <td>50.74100</td>\n",
       "      <td>3.228449</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115</td>\n",
       "      <td>88____:007::8885704:8885001:4:623:20210418</td>\n",
       "      <td>14</td>\n",
       "      <td>Tournai</td>\n",
       "      <td>8885001</td>\n",
       "      <td>06:23:00</td>\n",
       "      <td>06:23:00</td>\n",
       "      <td>4</td>\n",
       "      <td>TOURNAI</td>\n",
       "      <td>50.61313</td>\n",
       "      <td>3.396940</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431487</th>\n",
       "      <td>734</td>\n",
       "      <td>88____:007::8821105:8812005:22:1723:20210418</td>\n",
       "      <td>25</td>\n",
       "      <td>Bruxelles-Nord</td>\n",
       "      <td>8811270</td>\n",
       "      <td>17:01:00</td>\n",
       "      <td>17:01:00</td>\n",
       "      <td>19</td>\n",
       "      <td>VELTEM</td>\n",
       "      <td>50.90052</td>\n",
       "      <td>4.633520</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431488</th>\n",
       "      <td>734</td>\n",
       "      <td>88____:007::8821105:8812005:22:1723:20210418</td>\n",
       "      <td>25</td>\n",
       "      <td>Bruxelles-Nord</td>\n",
       "      <td>8811288</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>18</td>\n",
       "      <td>HERENT</td>\n",
       "      <td>50.90353</td>\n",
       "      <td>4.672190</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431489</th>\n",
       "      <td>734</td>\n",
       "      <td>88____:007::8821105:8812005:22:1723:20210418</td>\n",
       "      <td>25</td>\n",
       "      <td>Bruxelles-Nord</td>\n",
       "      <td>8819406</td>\n",
       "      <td>17:10:00</td>\n",
       "      <td>17:12:00</td>\n",
       "      <td>23</td>\n",
       "      <td>BRUSSELS AIRPORT-ZAVENTEM</td>\n",
       "      <td>50.89646</td>\n",
       "      <td>4.482072</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431490</th>\n",
       "      <td>734</td>\n",
       "      <td>88____:007::8821105:8812005:22:1723:20210418</td>\n",
       "      <td>25</td>\n",
       "      <td>Bruxelles-Nord</td>\n",
       "      <td>8821063</td>\n",
       "      <td>16:11:00</td>\n",
       "      <td>16:11:00</td>\n",
       "      <td>5</td>\n",
       "      <td>ANVERS-LUCHTBAL</td>\n",
       "      <td>51.24413</td>\n",
       "      <td>4.425033</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431491</th>\n",
       "      <td>734</td>\n",
       "      <td>88____:007::8821105:8812005:22:1723:20210418</td>\n",
       "      <td>25</td>\n",
       "      <td>Bruxelles-Nord</td>\n",
       "      <td>8821105</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>16:01:00</td>\n",
       "      <td>4</td>\n",
       "      <td>NOORDERKEMPEN (BRECHT)</td>\n",
       "      <td>51.35683</td>\n",
       "      <td>4.632200</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417593 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        route_id                                       trip_id  service_id  \\\n",
       "0            115    88____:007::8885704:8885001:4:523:20210418          14   \n",
       "1            115    88____:007::8885704:8885001:4:523:20210418          14   \n",
       "2            115    88____:007::8885704:8885001:4:523:20210418          14   \n",
       "3            115    88____:007::8885704:8885001:4:523:20210418          14   \n",
       "4            115    88____:007::8885704:8885001:4:623:20210418          14   \n",
       "...          ...                                           ...         ...   \n",
       "431487       734  88____:007::8821105:8812005:22:1723:20210418          25   \n",
       "431488       734  88____:007::8821105:8812005:22:1723:20210418          25   \n",
       "431489       734  88____:007::8821105:8812005:22:1723:20210418          25   \n",
       "431490       734  88____:007::8821105:8812005:22:1723:20210418          25   \n",
       "431491       734  88____:007::8821105:8812005:22:1723:20210418          25   \n",
       "\n",
       "         trip_headsign  stop_id arrival_time departure_time  stop_sequence  \\\n",
       "0              Tournai  8885001     05:23:00       05:23:00              4   \n",
       "1              Tournai  8885068     05:19:00       05:19:00              3   \n",
       "2              Tournai  8885753     05:12:00       05:12:00              2   \n",
       "3              Tournai  8885704     05:07:00       05:07:00              1   \n",
       "4              Tournai  8885001     06:23:00       06:23:00              4   \n",
       "...                ...      ...          ...            ...            ...   \n",
       "431487  Bruxelles-Nord  8811270     17:01:00       17:01:00             19   \n",
       "431488  Bruxelles-Nord  8811288     16:59:00       16:59:00             18   \n",
       "431489  Bruxelles-Nord  8819406     17:10:00       17:12:00             23   \n",
       "431490  Bruxelles-Nord  8821063     16:11:00       16:11:00              5   \n",
       "431491  Bruxelles-Nord  8821105     16:00:00       16:01:00              4   \n",
       "\n",
       "                        stop_name  stop_lat  stop_lon  country  \n",
       "0                         TOURNAI  50.61313  3.396940  Belgium  \n",
       "1                       FROYENNES  50.62989  3.354835  Belgium  \n",
       "2                        HERSEAUX  50.71390  3.245961  Belgium  \n",
       "3                        MOUSCRON  50.74100  3.228449  Belgium  \n",
       "4                         TOURNAI  50.61313  3.396940  Belgium  \n",
       "...                           ...       ...       ...      ...  \n",
       "431487                     VELTEM  50.90052  4.633520  Belgium  \n",
       "431488                     HERENT  50.90353  4.672190  Belgium  \n",
       "431489  BRUSSELS AIRPORT-ZAVENTEM  50.89646  4.482072  Belgium  \n",
       "431490            ANVERS-LUCHTBAL  51.24413  4.425033  Belgium  \n",
       "431491     NOORDERKEMPEN (BRECHT)  51.35683  4.632200  Belgium  \n",
       "\n",
       "[417593 rows x 12 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "railway_system_information_Belgium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for the space-of-stops representation of the railway systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Create a DataFrame with the departure time form the first stop sequence and with the one from last stop sequence for each trip_id'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Create a DataFrame with the departure time form the first stop sequence and with the one from last stop sequence for each trip_id'''\n",
    "\n",
    "def create_trip_departure_times(railway_system_information):\n",
    "    departure_time_first = railway_system_information.reset_index().loc[railway_system_information.reset_index().groupby(['trip_id'])['stop_sequence'].idxmin()][['route_id', 'trip_id', 'departure_time']].copy()\n",
    "    departure_time_first = departure_time_first.rename(columns = {'departure_time': 'departure_time_first'})\n",
    "    departure_time_last = railway_system_information.reset_index().loc[railway_system_information.reset_index().groupby(['trip_id'])['stop_sequence'].idxmax()][['route_id', 'trip_id', 'departure_time']].copy()\n",
    "    departure_time_last = departure_time_last.rename(columns = {'departure_time': 'departure_time_last'})\n",
    "    trip_departure_times = departure_time_first.merge(departure_time_last[['trip_id', 'departure_time_last']], on='trip_id')\n",
    "    return trip_departure_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Put the stop_names per trip_id in a list in the new trip_stops_sequence DataFrame and\\nCalculate the hash of the stop sequence in both order (ascending and descending)'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Put the stop_names per trip_id in a list in the new trip_stops_sequence DataFrame and\n",
    "Calculate the hash of the stop sequence in both order (ascending and descending)'''\n",
    "\n",
    "def create_trip_stop_sequence(trip_departure_times):    \n",
    "    #Put the stop_names per trip_id in a list in the new trip_stops_sequence DataFrame\n",
    "    trip_stop_sequence = trip_departure_times.groupby('trip_id')['stop_name'].apply(lambda group_series: group_series.tolist()).reset_index()\n",
    "    trip_stop_sequence.rename(columns={'stop_name':'stop_sequence'}, inplace=True)\n",
    "    #Calculate the hash of the stop sequence in both order (ascending and descending)\n",
    "    trip_stop_sequence['hash'] = trip_stop_sequence['stop_sequence'].apply(lambda x: hash(tuple(x)))\n",
    "    trip_stop_sequence['hash_inverse'] = trip_stop_sequence['stop_sequence'].apply(lambda x: hash(tuple(x[::-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regroup the days per service id in a set and count them'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Regroup the days per service id in a set and count them'''\n",
    "\n",
    "def create_service_id_dates(calendar_dates):\n",
    "    service_id_dates = calendar_dates.groupby('service_id')['date'].apply(lambda group_series: set(group_series.tolist())).reset_index()\n",
    "    service_id_dates.rename(columns={'date':'dates'}, inplace=True)\n",
    "    service_id_dates['count_service_id'] = service_id_dates['dates'].apply(lambda x: len(x))\n",
    "    return service_id_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Put the different trip_ids in a list and add the departure_time first and last lists'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Put the different trip_ids in a list and add the departure_time first and last lists'''\n",
    "\n",
    "def create_routes_hash(trips_hash):\n",
    "    common_columns = ['route_id','route_long_name','hash', 'hash_inverse', 'service_id']\n",
    "    routes_hash = trips_hash.groupby(common_columns)['trip_id'].apply(lambda group_series: group_series.tolist()).reset_index()\n",
    "    route_hash_dep_first = trips_hash.groupby(common_columns)['departure_time_first'].apply(lambda group_series: group_series.tolist()).reset_index()\n",
    "    route_hash_dep_last = trips_hash.groupby(common_columns)['departure_time_last'].apply(lambda group_series: group_series.tolist()).reset_index()\n",
    "    routes_hash = route_hash.merge(route_hash_dep_first, on= common_columns)\n",
    "    routes_hash = route_hash.merge(route_hash_dep_last, on= common_columns)\n",
    "    return routes_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Create DataFrames that will be used for the route_creation process'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Create DataFrames that will be used for the route_creation process'''\n",
    "\n",
    "def prepartion_space(railway_system_information, calendar_dates):    \n",
    "    #Sort values by the route_id, the trip_id, and the stop_sequence fields\n",
    "    railway_system_information.sort_values(by=['route_id', 'trip_id', 'stop_sequence'])\n",
    "\n",
    "    trip_departure_times = create_trip_departure_times(railway_system_information)\n",
    "\n",
    "    #Merge railway_system_information with trip_departure_times\n",
    "    trip_departure_times = railway_system_information.merge(trip_departure_times[['trip_id','departure_time_first','departure_time_last']], on='trip_id')\n",
    "\n",
    "    trip_stop_sequence = create_trip_stop_sequence(trip_departure_times)\n",
    "    \n",
    "    #Add the stop_sequence of stations to the trip_departure_times dataset by joining on trip_id\n",
    "    trips_hash = pd.merge(trip_departure_times, trip_stop_sequence, on='trip_id')\n",
    "    \n",
    "    service_id_dates = create_service_id_dates(calendar_dates)\n",
    "    \n",
    "    #Merge trips_hash with service_id_dates\n",
    "    trips_hash = pd.merge(trips_hash, service_id_dates, on='service_id', how='left')\n",
    "    \n",
    "    routes_hash = create_routes_hash(trips_hash)\n",
    "    \n",
    "    #Add the sequence of stops, dates and service_id_count to the route_hash_freq_dep dataset\n",
    "    routes_hash = pd.merge(routes_hash, trips_hash[['route_id','hash', 'hash_inverse', 'service_id','stop_sequence','dates','service_id_count']], on=['route_id', 'hash', 'hash_inverse', 'service_id'])\n",
    "    \n",
    "    #route_hash = route_hash_freq_seq.drop_duplicates( subset = ['route_id', 'hash', 'service_id'], keep = 'first')\n",
    "    \n",
    "    return route_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acutal preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belgium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
