{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3472,
     "status": "ok",
     "timestamp": 1616022178168,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "fxqEuGGdCZDS",
    "outputId": "b8082907-60f3-4243-d211-a50cf47a0ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in /Users/pol/opt/anaconda3/lib/python3.8/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /Users/pol/opt/anaconda3/lib/python3.8/site-packages (from geopy) (1.50)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3463,
     "status": "ok",
     "timestamp": 1616022178171,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "dZg2VPGmhu6F"
   },
   "outputs": [],
   "source": [
    "'''To import the required packages.'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzp7Oyi1hw36"
   },
   "source": [
    "# Import of the Swiss railway datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3457,
     "status": "ok",
     "timestamp": 1616022178172,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "_O0pAJn7hwkd"
   },
   "outputs": [],
   "source": [
    "'''To register the GitHub link with the Swiss data as a variable.'''\n",
    "datalink = \"https://raw.githubusercontent.com/polkuleuven/Thesis_Train/main/gtfs_train_Switzerland_1503/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9903,
     "status": "ok",
     "timestamp": 1616022184626,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "Y7myfthIh7AL",
    "outputId": "c125dfbc-d3aa-466d-b9b1-d1d0a984d491"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pol/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "'''Import all the GTFS data'''\n",
    "\n",
    "#To import the agency dataset that contains limited information about the Swiss SBB railway agency.\n",
    "agency_Switzerland = pd.read_csv(datalink + \"agency.txt\", sep=\",\")\n",
    "#To import the stops dataset that contains information about the ids, the names and the geographical coordinates of the Swiss SBB railway stations.\n",
    "stops_Switzerland = pd.read_csv(datalink + \"stops.txt\", sep=\",\")\n",
    "#To import the feed_info dataset that contains limited information about the Swiss SBB railway feed.\n",
    "feed_info_Switzerland = pd.read_csv(datalink + \"feed_info.txt\", sep=\",\")\n",
    "#To import the transfers dataset that gives the minimum transfer time to switch routes at each Swiss SBB railway station.\n",
    "transfers_not_cleaned_Switzerland = pd.read_csv(datalink + \"transfers.txt\", sep=\",\")\n",
    "#To import the routes dataset that provides the id, the name and the type of vehicle used for all Swiss SBB railway routes.\n",
    "routes_Switzerland = pd.read_csv(datalink + \"routes.txt\", sep=\",\")\n",
    "#To import the trips dataset that gives for all routes an overview of the trips and the headsigns of these trips belonging to the Swiss SBB railway route.\n",
    "#The service_id is an indication of all the dates this trip is valid (consultable in the calendar_dates dataset).\n",
    "trips_Switzerland = pd.read_csv(datalink + \"trips.txt\", sep=\",\")\n",
    "#To import the stop_times dataset that gives for all trips an overview of the ids of the stations served and the sequence in which these stations are served. \n",
    "#In addition, for all the trips the arrival and departure times at the stations served are given.\n",
    "stop_times_Switzerland = pd.read_csv(datalink + \"stop_times.txt\", sep=\",\")\n",
    "#To import the calendar dataset that gives the first and last date of all data observations.\n",
    "calendar_Switzerland = pd.read_csv(datalink + \"calendar.txt\", sep=\",\")\n",
    "#To import the calendar_dates dataset that gives for each service_id all the exact dates when that service_id is valid.\n",
    "calendar_dates_Switzerland = pd.read_csv(datalink + \"calendar_dates.txt\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAtGeRYBi8rP"
   },
   "source": [
    "# Cleaning of the Swiss railway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 9901,
     "status": "ok",
     "timestamp": 1616022184635,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "obHyfMjMi8d2",
    "outputId": "ce21ec71-f7bf-452f-896d-570078e4d1b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>agency_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>route_desc</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_url</th>\n",
       "      <th>route_color</th>\n",
       "      <th>route_text_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04236.06____.020:4236</td>\n",
       "      <td>06____</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>06____</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04700.06____.014:4700</td>\n",
       "      <td>06____</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04701.06____.002:4701</td>\n",
       "      <td>06____</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04701.06____.015:4701</td>\n",
       "      <td>06____</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49346</th>\n",
       "      <td>87945.L7____.001:5</td>\n",
       "      <td>L7____</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FFEA00</td>\n",
       "      <td>000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49347</th>\n",
       "      <td>87946.L7____.001:5</td>\n",
       "      <td>L7____</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FFEA00</td>\n",
       "      <td>000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49348</th>\n",
       "      <td>87947.L7____.001:5</td>\n",
       "      <td>L7____</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FFEA00</td>\n",
       "      <td>000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49349</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>L7____</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FFEA00</td>\n",
       "      <td>000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49350</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>L7____</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FFEA00</td>\n",
       "      <td>000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46037 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    route_id agency_id route_short_name route_long_name  \\\n",
       "0      04236.06____.020:4236    06____               RE         RE 4236   \n",
       "1      04700.06____.001:4700    06____               RE         RE 4700   \n",
       "2      04700.06____.014:4700    06____               RE         RE 4700   \n",
       "3      04701.06____.002:4701    06____               RE         RE 4701   \n",
       "4      04701.06____.015:4701    06____               RE         RE 4701   \n",
       "...                      ...       ...              ...             ...   \n",
       "49346     87945.L7____.001:5    L7____               S5             S 5   \n",
       "49347     87946.L7____.001:5    L7____               S5             S 5   \n",
       "49348     87947.L7____.001:5    L7____               S5             S 5   \n",
       "49349     87948.L7____.001:5    L7____               S5             S 5   \n",
       "49350     87949.L7____.001:5    L7____               S5             S 5   \n",
       "\n",
       "       route_desc  route_type  route_url route_color route_text_color  \n",
       "0             NaN           2        NaN         NaN              NaN  \n",
       "1             NaN           2        NaN         NaN              NaN  \n",
       "2             NaN           2        NaN         NaN              NaN  \n",
       "3             NaN           2        NaN         NaN              NaN  \n",
       "4             NaN           2        NaN         NaN              NaN  \n",
       "...           ...         ...        ...         ...              ...  \n",
       "49346         NaN           2        NaN      FFEA00           000000  \n",
       "49347         NaN           2        NaN      FFEA00           000000  \n",
       "49348         NaN           2        NaN      FFEA00           000000  \n",
       "49349         NaN           2        NaN      FFEA00           000000  \n",
       "49350         NaN           2        NaN      FFEA00           000000  \n",
       "\n",
       "[46037 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To clean the routes_Switzerland df.'''\n",
    "#To keep the train routes\n",
    "routes_cleaned_Switzerland = routes_Switzerland[routes_Switzerland['route_type'] == 2]\n",
    "routes_cleaned_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 10317,
     "status": "ok",
     "timestamp": 1616022185066,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "_X3xAvLriI-L",
    "outputId": "5285357b-bb9b-420e-d1fb-88471a827382"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pol/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>trip_short_name</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>bikes_allowed</th>\n",
       "      <th>attributes_ch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04236.06____.020:4236</td>\n",
       "      <td>19311</td>\n",
       "      <td>0:1</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>4236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>133763</td>\n",
       "      <td>1:1</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>4700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>1</td>\n",
       "      <td>1:2</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>4700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>13336</td>\n",
       "      <td>1:3</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>4700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>2610</td>\n",
       "      <td>1:4</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>4700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90223</th>\n",
       "      <td>87947.L7____.001:5</td>\n",
       "      <td>2364</td>\n",
       "      <td>49348:1</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90224</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>56518</td>\n",
       "      <td>49349:1</td>\n",
       "      <td>LORRACH HBF</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90225</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>17102</td>\n",
       "      <td>49349:2</td>\n",
       "      <td>ZELL (WIESENTAL)</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90226</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>17102</td>\n",
       "      <td>49350:1</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90227</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>56518</td>\n",
       "      <td>49350:2</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    route_id  service_id  trip_id     trip_headsign  \\\n",
       "0      04236.06____.020:4236       19311      0:1     KARLSRUHE HBF   \n",
       "1      04700.06____.001:4700      133763      1:1     KARLSRUHE HBF   \n",
       "2      04700.06____.001:4700           1      1:2     KARLSRUHE HBF   \n",
       "3      04700.06____.001:4700       13336      1:3     KARLSRUHE HBF   \n",
       "4      04700.06____.001:4700        2610      1:4     KARLSRUHE HBF   \n",
       "...                      ...         ...      ...               ...   \n",
       "90223     87947.L7____.001:5        2364  49348:1     WEIL AM RHEIN   \n",
       "90224     87948.L7____.001:5       56518  49349:1       LORRACH HBF   \n",
       "90225     87948.L7____.001:5       17102  49349:2  ZELL (WIESENTAL)   \n",
       "90226     87949.L7____.001:5       17102  49350:1     WEIL AM RHEIN   \n",
       "90227     87949.L7____.001:5       56518  49350:2     WEIL AM RHEIN   \n",
       "\n",
       "      trip_short_name  direction_id  block_id  shape_id  bikes_allowed  \\\n",
       "0                4236           NaN       NaN       NaN              0   \n",
       "1                4700           NaN       NaN       NaN              0   \n",
       "2                4700           NaN       NaN       NaN              0   \n",
       "3                4700           NaN       NaN       NaN              0   \n",
       "4                4700           NaN       NaN       NaN              0   \n",
       "...               ...           ...       ...       ...            ...   \n",
       "90223               5           NaN       NaN       NaN              0   \n",
       "90224               5           NaN       NaN       NaN              0   \n",
       "90225               5           NaN       NaN       NaN              0   \n",
       "90226               5           NaN       NaN       NaN              0   \n",
       "90227               5           NaN       NaN       NaN              0   \n",
       "\n",
       "      attributes_ch  \n",
       "0                MO  \n",
       "1                MO  \n",
       "2                MO  \n",
       "3                MO  \n",
       "4                MO  \n",
       "...             ...  \n",
       "90223            MO  \n",
       "90224            MO  \n",
       "90225            MO  \n",
       "90226            MO  \n",
       "90227            MO  \n",
       "\n",
       "[86914 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To clean the trips_Switzerland df.'''\n",
    "# To remove the routes that are not train routes\n",
    "no_route_id_train_route = routes_Switzerland.loc[routes_Switzerland['route_type'] != 2, 'route_id']\n",
    "trips_cleaned_Switzerland = trips_Switzerland[(~trips_Switzerland['route_id'].isin(no_route_id_train_route))]\n",
    "\n",
    "# To remove the accents from the trip_headsign and to change to uppercase\n",
    "trips_cleaned_Switzerland.loc[:,'trip_headsign'] = trips_cleaned_Switzerland.loc[:,'trip_headsign'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "trips_cleaned_Switzerland.loc[:,'trip_headsign'] = trips_cleaned_Switzerland.loc[:,'trip_headsign'].str.upper()\n",
    "trips_cleaned_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 12551,
     "status": "ok",
     "timestamp": 1616022187323,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "uOpPTi1pjB3p",
    "outputId": "cabf6357-66f0-4f18-b3cf-b208ddf77ee2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pol/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_headsign</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "      <th>attributes_ch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:16:00</td>\n",
       "      <td>18:16:00</td>\n",
       "      <td>8014554</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:28:00</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>8014534</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:40:00</td>\n",
       "      <td>18:40:00</td>\n",
       "      <td>8014529</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:49:00</td>\n",
       "      <td>18:50:00</td>\n",
       "      <td>8014521</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:58:00</td>\n",
       "      <td>18:59:00</td>\n",
       "      <td>8014518</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034556</th>\n",
       "      <td>49350:2</td>\n",
       "      <td>10:38:00</td>\n",
       "      <td>10:38:00</td>\n",
       "      <td>8069220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034557</th>\n",
       "      <td>49350:2</td>\n",
       "      <td>10:40:00</td>\n",
       "      <td>10:40:00</td>\n",
       "      <td>8014429</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034558</th>\n",
       "      <td>49350:2</td>\n",
       "      <td>10:41:00</td>\n",
       "      <td>10:42:00</td>\n",
       "      <td>8060979</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034559</th>\n",
       "      <td>49350:2</td>\n",
       "      <td>10:43:00</td>\n",
       "      <td>10:43:00</td>\n",
       "      <td>8060978</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034560</th>\n",
       "      <td>49350:2</td>\n",
       "      <td>10:45:00</td>\n",
       "      <td>10:45:00</td>\n",
       "      <td>8014428</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991436 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         trip_id arrival_time departure_time  stop_id  stop_sequence  \\\n",
       "0            0:1     18:16:00       18:16:00  8014554              0   \n",
       "1            0:1     18:28:00       18:30:00  8014534              1   \n",
       "2            0:1     18:40:00       18:40:00  8014529              2   \n",
       "3            0:1     18:49:00       18:50:00  8014521              3   \n",
       "4            0:1     18:58:00       18:59:00  8014518              4   \n",
       "...          ...          ...            ...      ...            ...   \n",
       "1034556  49350:2     10:38:00       10:38:00  8069220              3   \n",
       "1034557  49350:2     10:40:00       10:40:00  8014429              4   \n",
       "1034558  49350:2     10:41:00       10:42:00  8060979              5   \n",
       "1034559  49350:2     10:43:00       10:43:00  8060978              6   \n",
       "1034560  49350:2     10:45:00       10:45:00  8014428              7   \n",
       "\n",
       "         stop_headsign  pickup_type  drop_off_type  shape_dist_traveled  \\\n",
       "0                  NaN            0              0                  NaN   \n",
       "1                  NaN            0              0                  NaN   \n",
       "2                  NaN            0              0                  NaN   \n",
       "3                  NaN            0              0                  NaN   \n",
       "4                  NaN            0              0                  NaN   \n",
       "...                ...          ...            ...                  ...   \n",
       "1034556            NaN            3              3                  NaN   \n",
       "1034557            NaN            3              3                  NaN   \n",
       "1034558            NaN            3              3                  NaN   \n",
       "1034559            NaN            3              3                  NaN   \n",
       "1034560            NaN            0              0                  NaN   \n",
       "\n",
       "        attributes_ch  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "1034556             X  \n",
       "1034557             X  \n",
       "1034558             X  \n",
       "1034559             X  \n",
       "1034560           NaN  \n",
       "\n",
       "[991436 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To clean the stop_times_Switzerland df.'''\n",
    "# To remove the stop_times trip_ids that are not trip_ids that belong to train routes\n",
    "no_trip_id_train_route = trips_Switzerland.loc[trips_Switzerland['route_id'].isin(no_route_id_train_route), 'trip_id']\n",
    "stop_times_cleaned_Switzerland = stop_times_Switzerland[(~stop_times_Switzerland['trip_id'].isin(no_trip_id_train_route))]\n",
    "\n",
    "# To remove the superfluous characters of the stop_id (: and platform_code)\n",
    "stop_times_cleaned_Switzerland_column = stop_times_cleaned_Switzerland['stop_id'].str.split(':').str[0]\n",
    "stop_times_cleaned_Switzerland.loc[:,'stop_id'] = stop_times_cleaned_Switzerland_column\n",
    "\n",
    "# To make the stop_ids numerical and to remove the duplicate stop_ids\n",
    "stop_times_cleaned_Switzerland.loc[:,'stop_id'] = stop_times_cleaned_Switzerland.loc[:,'stop_id'].astype(np.int64)\n",
    "stop_times_cleaned_Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 12542,
     "status": "ok",
     "timestamp": 1616022187326,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "02b2RbGPjDnM"
   },
   "source": [
    "''' To clean the stops_Switzerland df   (1).'''\n",
    "##### To select all stops that appear in the stop_times df\n",
    "stops_cleaned_df_Switzerland = stop_times_cleaned_Switzerland[['stop_id']]\n",
    "stops_cleaned_df_Switzerland = stops_cleaned_df_Switzerland.drop_duplicates()\n",
    "\n",
    "##### To make the stop_id attribute in the initial stops_Switzerland df numerical\n",
    "stops_initial_Switzerland_column = stops_Switzerland['stop_id'].str.split(':').str[0]\n",
    "stops_initial_Switzerland = stops_Switzerland.copy()\n",
    "stops_initial_Switzerland.loc[:,'stop_id'] = stops_initial_Switzerland_column\n",
    "\n",
    "##### To make the stop_ids numerical and to remove the duplicate stop_ids\n",
    "stops_initial_Switzerland = stops_initial_Switzerland[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']]\n",
    "stops_initial_Switzerland.loc[:,'stop_id'] = stops_initial_Switzerland.loc[:,'stop_id'].astype(np.int64)\n",
    "stops_initial_Switzerland = stops_initial_Switzerland.drop_duplicates()\n",
    "\n",
    "##### To remove the accents from the stop_name and to change to uppercase\n",
    "stops_initial_Switzerland.loc[:,'stop_name'] = stops_initial_Switzerland.loc[:,'stop_name'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "stops_initial_Switzerland.loc[:,'stop_name'] = stops_initial_Switzerland.loc[:,'stop_name'].str.upper()\n",
    "\n",
    "##### To merge the stops_cleaned_df_Switzerland and the stops_initial_Switzerland df\n",
    "stops_cleaned_Switzerland = pd.merge(stops_initial_Switzerland, stops_cleaned_df_Switzerland, on = 'stop_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 2840440,
     "status": "ok",
     "timestamp": 1616025015229,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "a2Q3p9FAjG5m"
   },
   "source": [
    "''' To clean the stops_Switzerland df   (2).'''\n",
    "##### To initialize the Nominatim API to get the location from the input string \n",
    "geolocator = Nominatim(user_agent=\"application\")\n",
    "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=0.2)\n",
    "\n",
    "##### To get the location with the geolocator.reverse() function and to extract the country from the location instance\n",
    "country_list = []\n",
    "for index, row in stops_cleaned_Switzerland.iterrows():\n",
    "    latitude = row['stop_lat']\n",
    "    longitude = row['stop_lon']\n",
    "    # To assign the latitude and longitude into a geolocator.reverse() method\n",
    "    location = reverse((latitude, longitude), language='en', exactly_one=True)\n",
    "    # To get the country from the given list and parsed into a dictionary with raw function()\n",
    "    address = location.raw['address']\n",
    "    country = address.get('country', '')\n",
    "    country_list.append(country)\n",
    "\n",
    "##### To add the values of country_list as a new attribute country     \n",
    "stops_cleaned_Switzerland.loc[:,'country'] = country_list\n",
    "stops_cleaned_Switzerland\n",
    "\n",
    "##### To calculate the total number of Belgian stations in the stops_cleaned dataset\n",
    "swiss_stops_Switzerland = stops_cleaned_Switzerland[stops_cleaned_Switzerland['country'] == 'Switzerland']\n",
    "swiss_stops_Switzerland_series = stops_cleaned_Switzerland.loc[stops_cleaned_Switzerland['country'] == 'Switzerland', 'stop_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "swiss_stops_Switzerland_series.to_csv(r'/Users/pol/Desktop/CSV_export/swiss_stops_Switzerland_series.csv', index = False, header=True, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stops_cleaned_Switzerland.to_csv(r'/Users/pol/Desktop/CSV_export/stops_cleaned_Switzerland.csv', index = False, header=True, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import the cleaned version of the stops with their country'''\n",
    "stops_cleaned_Switzerland = pd.read_csv(\"https://raw.githubusercontent.com/polkuleuven/Thesis_Train/main/stops_cleaned/stops_cleaned_Switzerland.csv\", sep=\",\")\n",
    "swiss_stops_Switzerland_series = pd.read_csv(\"https://raw.githubusercontent.com/polkuleuven/Thesis_Train/main/country_stops_series/swiss_stops_Switzerland_series.csv\", sep=\",\")['stop_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>date</th>\n",
       "      <th>exception_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5</td>\n",
       "      <td>20210315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>20210316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5</td>\n",
       "      <td>20210317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5</td>\n",
       "      <td>20210318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5</td>\n",
       "      <td>20210319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536188</th>\n",
       "      <td>12559</td>\n",
       "      <td>20210711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536189</th>\n",
       "      <td>12559</td>\n",
       "      <td>20210712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536190</th>\n",
       "      <td>12559</td>\n",
       "      <td>20210713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536341</th>\n",
       "      <td>12560</td>\n",
       "      <td>20210603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536342</th>\n",
       "      <td>12560</td>\n",
       "      <td>20210513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>521828 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         service_id      date  exception_type\n",
       "63                5  20210315               1\n",
       "64                5  20210316               1\n",
       "65                5  20210317               1\n",
       "66                5  20210318               1\n",
       "67                5  20210319               1\n",
       "...             ...       ...             ...\n",
       "1536188       12559  20210711               1\n",
       "1536189       12559  20210712               1\n",
       "1536190       12559  20210713               1\n",
       "1536341       12560  20210603               1\n",
       "1536342       12560  20210513               1\n",
       "\n",
       "[521828 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''filter the dats from the selected begin to the end date'''\n",
    "#here we used 4 months\n",
    "begin_date = 20210314\n",
    "end_date = 20210713\n",
    "filtered_calendar_dates_Switzerland = calendar_dates_Switzerland.copy()\n",
    "filtered_calendar_dates_Switzerland = filtered_calendar_dates_Switzerland.drop(filtered_calendar_dates_Switzerland[(filtered_calendar_dates_Switzerland['date'] > end_date) |(filtered_calendar_dates_Switzerland['date'] < begin_date)].index)\n",
    "filtered_calendar_dates_Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbZGKW0yjLPT"
   },
   "source": [
    "# Exploratory data analysis with the Swiss railway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2840459,
     "status": "ok",
     "timestamp": 1616025015253,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "ICbRkTypjMH5",
    "outputId": "0f0ec81e-2e76-4ddf-b0ce-1373faaff970"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46037"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To calculate the number of unique route_ids '''\n",
    "set_routes_Switzerland = {r for r in routes_cleaned_Switzerland['route_id']}\n",
    "len(set_routes_Switzerland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2840457,
     "status": "ok",
     "timestamp": 1616025015256,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "JbQivno0jOIV",
    "outputId": "ce0d71a1-f7d8-4629-8192-7fcf7849ae91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2608"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To calculate the total number of stations in the stops_cleaned_Switzerland dataset'''\n",
    "set_stations_Switzerland = {s for s in stops_cleaned_Switzerland['stop_id']}\n",
    "len(set_stations_Switzerland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2840454,
     "status": "ok",
     "timestamp": 1616025015258,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "BG0t-i9Zj3LY",
    "outputId": "e1c04f28-ebe6-4740-963f-cc504deaf848"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1762"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To calculate the total number of Swiss stations in the stops_cleaned dataset'''\n",
    "len(swiss_stops_Switzerland_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwH9sY0Zj439"
   },
   "source": [
    "# **Preparation for the L-space representation of the Swiss railway system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2840451,
     "status": "ok",
     "timestamp": 1616025015260,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "JB_GTikFj5Nf",
    "outputId": "b296ef1a-e3d6-476f-bd29-91ef0dbc4bfa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04236.06____.020:4236</td>\n",
       "      <td>19311</td>\n",
       "      <td>0:1</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>133763</td>\n",
       "      <td>1:1</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>1</td>\n",
       "      <td>1:2</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>13336</td>\n",
       "      <td>1:3</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>2610</td>\n",
       "      <td>1:4</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE 4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86909</th>\n",
       "      <td>87947.L7____.001:5</td>\n",
       "      <td>2364</td>\n",
       "      <td>49348:1</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86910</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>56518</td>\n",
       "      <td>49349:1</td>\n",
       "      <td>LORRACH HBF</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86911</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>17102</td>\n",
       "      <td>49349:2</td>\n",
       "      <td>ZELL (WIESENTAL)</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86912</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>17102</td>\n",
       "      <td>49350:1</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86913</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>56518</td>\n",
       "      <td>49350:2</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>S5</td>\n",
       "      <td>S 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    route_id  service_id  trip_id     trip_headsign  \\\n",
       "0      04236.06____.020:4236       19311      0:1     KARLSRUHE HBF   \n",
       "1      04700.06____.001:4700      133763      1:1     KARLSRUHE HBF   \n",
       "2      04700.06____.001:4700           1      1:2     KARLSRUHE HBF   \n",
       "3      04700.06____.001:4700       13336      1:3     KARLSRUHE HBF   \n",
       "4      04700.06____.001:4700        2610      1:4     KARLSRUHE HBF   \n",
       "...                      ...         ...      ...               ...   \n",
       "86909     87947.L7____.001:5        2364  49348:1     WEIL AM RHEIN   \n",
       "86910     87948.L7____.001:5       56518  49349:1       LORRACH HBF   \n",
       "86911     87948.L7____.001:5       17102  49349:2  ZELL (WIESENTAL)   \n",
       "86912     87949.L7____.001:5       17102  49350:1     WEIL AM RHEIN   \n",
       "86913     87949.L7____.001:5       56518  49350:2     WEIL AM RHEIN   \n",
       "\n",
       "      route_short_name route_long_name  \n",
       "0                   RE         RE 4236  \n",
       "1                   RE         RE 4700  \n",
       "2                   RE         RE 4700  \n",
       "3                   RE         RE 4700  \n",
       "4                   RE         RE 4700  \n",
       "...                ...             ...  \n",
       "86909               S5             S 5  \n",
       "86910               S5             S 5  \n",
       "86911               S5             S 5  \n",
       "86912               S5             S 5  \n",
       "86913               S5             S 5  \n",
       "\n",
       "[86914 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To merge a selection of the trips dataset and a selection of the routes dataset on route_id'''\n",
    "trips_routes_Switzerland = pd.merge(trips_cleaned_Switzerland[['route_id','service_id','trip_id', 'trip_headsign']], routes_cleaned_Switzerland[['route_id', 'route_short_name', 'route_long_name']], on='route_id')\n",
    "trips_routes_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2840750,
     "status": "ok",
     "timestamp": 1616025015566,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "l_4nx7-nkFdW",
    "outputId": "3c8b6c1a-ec8d-4186-c732-4ee1a32c6d52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:16:00</td>\n",
       "      <td>18:16:00</td>\n",
       "      <td>8014554</td>\n",
       "      <td>0</td>\n",
       "      <td>ENGEN</td>\n",
       "      <td>47.856347</td>\n",
       "      <td>8.772786</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7:1</td>\n",
       "      <td>06:32:00</td>\n",
       "      <td>06:33:00</td>\n",
       "      <td>8014554</td>\n",
       "      <td>4</td>\n",
       "      <td>ENGEN</td>\n",
       "      <td>47.856347</td>\n",
       "      <td>8.772786</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7:2</td>\n",
       "      <td>06:32:00</td>\n",
       "      <td>06:33:00</td>\n",
       "      <td>8014554</td>\n",
       "      <td>4</td>\n",
       "      <td>ENGEN</td>\n",
       "      <td>47.856347</td>\n",
       "      <td>8.772786</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12:1</td>\n",
       "      <td>07:18:00</td>\n",
       "      <td>07:19:00</td>\n",
       "      <td>8014554</td>\n",
       "      <td>12</td>\n",
       "      <td>ENGEN</td>\n",
       "      <td>47.856347</td>\n",
       "      <td>8.772786</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12:2</td>\n",
       "      <td>07:18:00</td>\n",
       "      <td>07:19:00</td>\n",
       "      <td>8014554</td>\n",
       "      <td>12</td>\n",
       "      <td>ENGEN</td>\n",
       "      <td>47.856347</td>\n",
       "      <td>8.772786</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991431</th>\n",
       "      <td>49275:2</td>\n",
       "      <td>24:04:00</td>\n",
       "      <td>24:04:00</td>\n",
       "      <td>8014439</td>\n",
       "      <td>2</td>\n",
       "      <td>RIEHEN</td>\n",
       "      <td>47.583156</td>\n",
       "      <td>7.652008</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991432</th>\n",
       "      <td>49276:1</td>\n",
       "      <td>24:14:00</td>\n",
       "      <td>24:14:00</td>\n",
       "      <td>8014439</td>\n",
       "      <td>14</td>\n",
       "      <td>RIEHEN</td>\n",
       "      <td>47.583156</td>\n",
       "      <td>7.652008</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991433</th>\n",
       "      <td>49276:2</td>\n",
       "      <td>24:14:00</td>\n",
       "      <td>24:14:00</td>\n",
       "      <td>8014439</td>\n",
       "      <td>14</td>\n",
       "      <td>RIEHEN</td>\n",
       "      <td>47.583156</td>\n",
       "      <td>7.652008</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991434</th>\n",
       "      <td>49276:3</td>\n",
       "      <td>24:14:00</td>\n",
       "      <td>24:14:00</td>\n",
       "      <td>8014439</td>\n",
       "      <td>14</td>\n",
       "      <td>RIEHEN</td>\n",
       "      <td>47.583156</td>\n",
       "      <td>7.652008</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991435</th>\n",
       "      <td>49277:1</td>\n",
       "      <td>01:13:00</td>\n",
       "      <td>01:13:00</td>\n",
       "      <td>8014439</td>\n",
       "      <td>14</td>\n",
       "      <td>RIEHEN</td>\n",
       "      <td>47.583156</td>\n",
       "      <td>7.652008</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991436 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trip_id arrival_time departure_time  stop_id  stop_sequence stop_name  \\\n",
       "0           0:1     18:16:00       18:16:00  8014554              0     ENGEN   \n",
       "1           7:1     06:32:00       06:33:00  8014554              4     ENGEN   \n",
       "2           7:2     06:32:00       06:33:00  8014554              4     ENGEN   \n",
       "3          12:1     07:18:00       07:19:00  8014554             12     ENGEN   \n",
       "4          12:2     07:18:00       07:19:00  8014554             12     ENGEN   \n",
       "...         ...          ...            ...      ...            ...       ...   \n",
       "991431  49275:2     24:04:00       24:04:00  8014439              2    RIEHEN   \n",
       "991432  49276:1     24:14:00       24:14:00  8014439             14    RIEHEN   \n",
       "991433  49276:2     24:14:00       24:14:00  8014439             14    RIEHEN   \n",
       "991434  49276:3     24:14:00       24:14:00  8014439             14    RIEHEN   \n",
       "991435  49277:1     01:13:00       01:13:00  8014439             14    RIEHEN   \n",
       "\n",
       "         stop_lat  stop_lon      country  \n",
       "0       47.856347  8.772786      Germany  \n",
       "1       47.856347  8.772786      Germany  \n",
       "2       47.856347  8.772786      Germany  \n",
       "3       47.856347  8.772786      Germany  \n",
       "4       47.856347  8.772786      Germany  \n",
       "...           ...       ...          ...  \n",
       "991431  47.583156  7.652008  Switzerland  \n",
       "991432  47.583156  7.652008  Switzerland  \n",
       "991433  47.583156  7.652008  Switzerland  \n",
       "991434  47.583156  7.652008  Switzerland  \n",
       "991435  47.583156  7.652008  Switzerland  \n",
       "\n",
       "[991436 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To merge a selection of the stop_times_cleaned_Switzerland dataset with the stops_cleaned_Switzerland dataset'''\n",
    "stop_times_stops_Switzerland = pd.merge(stop_times_cleaned_Switzerland[['trip_id','arrival_time', 'departure_time','stop_id','stop_sequence']], stops_cleaned_Switzerland, on='stop_id')\n",
    "stop_times_stops_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "executionInfo": {
     "elapsed": 2841594,
     "status": "ok",
     "timestamp": 1616025016418,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "VJRxCsGYkHVJ",
    "outputId": "c497ea8e-e4f5-46d2-e732-42814210cefd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>766843</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>936</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>8504392</td>\n",
       "      <td>0</td>\n",
       "      <td>LES BRENETS</td>\n",
       "      <td>47.067210</td>\n",
       "      <td>6.707389</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766844</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>936</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>05:53:00</td>\n",
       "      <td>05:54:00</td>\n",
       "      <td>8504391</td>\n",
       "      <td>1</td>\n",
       "      <td>LES FRETES</td>\n",
       "      <td>47.058580</td>\n",
       "      <td>6.725787</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766845</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>936</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>05:54:00</td>\n",
       "      <td>05:55:00</td>\n",
       "      <td>8530260</td>\n",
       "      <td>2</td>\n",
       "      <td>LE LOCLE LE CHALET</td>\n",
       "      <td>47.055918</td>\n",
       "      <td>6.738986</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766842</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>936</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>05:58:00</td>\n",
       "      <td>05:58:00</td>\n",
       "      <td>8504316</td>\n",
       "      <td>3</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>47.057861</td>\n",
       "      <td>6.746153</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766847</th>\n",
       "      <td>00001.000044.028:1</td>\n",
       "      <td>869</td>\n",
       "      <td>33249:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>06:08:00</td>\n",
       "      <td>06:08:00</td>\n",
       "      <td>8504392</td>\n",
       "      <td>0</td>\n",
       "      <td>LES BRENETS</td>\n",
       "      <td>47.067210</td>\n",
       "      <td>6.707389</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631389</th>\n",
       "      <td>96814.000011.101:96814</td>\n",
       "      <td>116609</td>\n",
       "      <td>23295:1</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>TER</td>\n",
       "      <td>TER 96814</td>\n",
       "      <td>12:56:00</td>\n",
       "      <td>13:05:00</td>\n",
       "      <td>8774500</td>\n",
       "      <td>1</td>\n",
       "      <td>BELLEGARDE (AIN)</td>\n",
       "      <td>46.110918</td>\n",
       "      <td>5.825962</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631388</th>\n",
       "      <td>96814.000011.101:96814</td>\n",
       "      <td>116609</td>\n",
       "      <td>23295:1</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>TER</td>\n",
       "      <td>TER 96814</td>\n",
       "      <td>14:33:00</td>\n",
       "      <td>14:33:00</td>\n",
       "      <td>8772319</td>\n",
       "      <td>2</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>45.760564</td>\n",
       "      <td>4.859990</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631390</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>44307</td>\n",
       "      <td>23296:1</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>TER</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>19:26:00</td>\n",
       "      <td>19:26:00</td>\n",
       "      <td>8501008</td>\n",
       "      <td>0</td>\n",
       "      <td>GENEVE</td>\n",
       "      <td>46.210213</td>\n",
       "      <td>6.142452</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631392</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>44307</td>\n",
       "      <td>23296:1</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>TER</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>19:58:00</td>\n",
       "      <td>20:02:00</td>\n",
       "      <td>8774500</td>\n",
       "      <td>1</td>\n",
       "      <td>BELLEGARDE (AIN)</td>\n",
       "      <td>46.110918</td>\n",
       "      <td>5.825962</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631391</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>44307</td>\n",
       "      <td>23296:1</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>TER</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>21:34:00</td>\n",
       "      <td>21:34:00</td>\n",
       "      <td>8772319</td>\n",
       "      <td>2</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>45.760564</td>\n",
       "      <td>4.859990</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991436 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      route_id  service_id  trip_id   trip_headsign  \\\n",
       "766843      00001.000044.018:1         936  33248:1        LE LOCLE   \n",
       "766844      00001.000044.018:1         936  33248:1        LE LOCLE   \n",
       "766845      00001.000044.018:1         936  33248:1        LE LOCLE   \n",
       "766842      00001.000044.018:1         936  33248:1        LE LOCLE   \n",
       "766847      00001.000044.028:1         869  33249:1        LE LOCLE   \n",
       "...                        ...         ...      ...             ...   \n",
       "631389  96814.000011.101:96814      116609  23295:1  LYON PART DIEU   \n",
       "631388  96814.000011.101:96814      116609  23295:1  LYON PART DIEU   \n",
       "631390  96818.000011.101:96818       44307  23296:1  LYON PART DIEU   \n",
       "631392  96818.000011.101:96818       44307  23296:1  LYON PART DIEU   \n",
       "631391  96818.000011.101:96818       44307  23296:1  LYON PART DIEU   \n",
       "\n",
       "       route_short_name route_long_name arrival_time departure_time  stop_id  \\\n",
       "766843                R             R 1     05:50:00       05:50:00  8504392   \n",
       "766844                R             R 1     05:53:00       05:54:00  8504391   \n",
       "766845                R             R 1     05:54:00       05:55:00  8530260   \n",
       "766842                R             R 1     05:58:00       05:58:00  8504316   \n",
       "766847                R             R 1     06:08:00       06:08:00  8504392   \n",
       "...                 ...             ...          ...            ...      ...   \n",
       "631389              TER       TER 96814     12:56:00       13:05:00  8774500   \n",
       "631388              TER       TER 96814     14:33:00       14:33:00  8772319   \n",
       "631390              TER       TER 96818     19:26:00       19:26:00  8501008   \n",
       "631392              TER       TER 96818     19:58:00       20:02:00  8774500   \n",
       "631391              TER       TER 96818     21:34:00       21:34:00  8772319   \n",
       "\n",
       "        stop_sequence           stop_name   stop_lat  stop_lon      country  \n",
       "766843              0         LES BRENETS  47.067210  6.707389  Switzerland  \n",
       "766844              1          LES FRETES  47.058580  6.725787  Switzerland  \n",
       "766845              2  LE LOCLE LE CHALET  47.055918  6.738986  Switzerland  \n",
       "766842              3            LE LOCLE  47.057861  6.746153  Switzerland  \n",
       "766847              0         LES BRENETS  47.067210  6.707389  Switzerland  \n",
       "...               ...                 ...        ...       ...          ...  \n",
       "631389              1    BELLEGARDE (AIN)  46.110918  5.825962       France  \n",
       "631388              2      LYON PART DIEU  45.760564  4.859990       France  \n",
       "631390              0              GENEVE  46.210213  6.142452  Switzerland  \n",
       "631392              1    BELLEGARDE (AIN)  46.110918  5.825962       France  \n",
       "631391              2      LYON PART DIEU  45.760564  4.859990       France  \n",
       "\n",
       "[991436 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To merge a selection of the stop_times_stops_Switzerland dataset with the trips_routes_Switzerland dataset.'''\n",
    "trips_routes_stop_times_stops_Switzerland = pd.merge(trips_routes_Switzerland, stop_times_stops_Switzerland, on='trip_id')\n",
    "trips_routes_stop_times_stops_Switzerland = trips_routes_stop_times_stops_Switzerland.sort_values(by=['route_id', 'trip_id', 'stop_sequence'])\n",
    "trips_routes_stop_times_stops_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>departure_time_first</th>\n",
       "      <th>departure_time_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04236.06____.020:4236</td>\n",
       "      <td>0:1</td>\n",
       "      <td>18:16:00</td>\n",
       "      <td>20:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10834.000011.101:8</td>\n",
       "      <td>10000:1</td>\n",
       "      <td>19:48:00</td>\n",
       "      <td>22:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10834.000011.102:8</td>\n",
       "      <td>10001:1</td>\n",
       "      <td>20:32:00</td>\n",
       "      <td>21:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10834.000011.103:8</td>\n",
       "      <td>10002:1</td>\n",
       "      <td>19:48:00</td>\n",
       "      <td>22:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10834.000011.104:8</td>\n",
       "      <td>10003:1</td>\n",
       "      <td>19:48:00</td>\n",
       "      <td>22:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86909</th>\n",
       "      <td>04725.06____.014:4725</td>\n",
       "      <td>99:1</td>\n",
       "      <td>12:07:00</td>\n",
       "      <td>13:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86910</th>\n",
       "      <td>04704.06____.007:4704</td>\n",
       "      <td>9:1</td>\n",
       "      <td>05:35:00</td>\n",
       "      <td>07:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86911</th>\n",
       "      <td>04704.06____.007:4704</td>\n",
       "      <td>9:2</td>\n",
       "      <td>05:35:00</td>\n",
       "      <td>07:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86912</th>\n",
       "      <td>04704.06____.007:4704</td>\n",
       "      <td>9:3</td>\n",
       "      <td>05:35:00</td>\n",
       "      <td>07:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86913</th>\n",
       "      <td>04704.06____.007:4704</td>\n",
       "      <td>9:4</td>\n",
       "      <td>05:35:00</td>\n",
       "      <td>07:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    route_id  trip_id departure_time_first departure_time_last\n",
       "0      04236.06____.020:4236      0:1             18:16:00            20:49:00\n",
       "1         10834.000011.101:8  10000:1             19:48:00            22:22:00\n",
       "2         10834.000011.102:8  10001:1             20:32:00            21:50:00\n",
       "3         10834.000011.103:8  10002:1             19:48:00            22:15:00\n",
       "4         10834.000011.104:8  10003:1             19:48:00            22:22:00\n",
       "...                      ...      ...                  ...                 ...\n",
       "86909  04725.06____.014:4725     99:1             12:07:00            13:20:00\n",
       "86910  04704.06____.007:4704      9:1             05:35:00            07:50:00\n",
       "86911  04704.06____.007:4704      9:2             05:35:00            07:50:00\n",
       "86912  04704.06____.007:4704      9:3             05:35:00            07:50:00\n",
       "86913  04704.06____.007:4704      9:4             05:35:00            07:50:00\n",
       "\n",
       "[86914 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Creates the a dataframe with the departure time form the first stop sequence and with the one from last stop sequence for each trip_id'''\n",
    "departure_time_first = trips_routes_stop_times_stops_Switzerland.reset_index().loc[trips_routes_stop_times_stops_Switzerland.reset_index().groupby(['trip_id'])['stop_sequence'].idxmin()][['route_id', 'trip_id', 'departure_time']].copy()\n",
    "departure_time_first = departure_time_first.rename(columns = {'departure_time': 'departure_time_first'})\n",
    "departure_time_last = trips_routes_stop_times_stops_Switzerland.reset_index().loc[trips_routes_stop_times_stops_Switzerland.reset_index().groupby(['trip_id'])['stop_sequence'].idxmax()][['route_id', 'trip_id', 'departure_time']].copy()\n",
    "departure_time_last = departure_time_last.rename(columns = {'departure_time': 'departure_time_last'})\n",
    "departure_times_Switzerland = departure_time_first.merge(departure_time_last[['trip_id', 'departure_time_last']], on='trip_id')\n",
    "departure_times_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2842979,
     "status": "ok",
     "timestamp": 1616025017812,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "pejQDim2kJ1l",
    "outputId": "c05a6420-4545-4992-c865-2d4b5ac256d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>0</td>\n",
       "      <td>LES BRENETS</td>\n",
       "      <td>47.067210</td>\n",
       "      <td>6.707389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>1</td>\n",
       "      <td>LES FRETES</td>\n",
       "      <td>47.058580</td>\n",
       "      <td>6.725787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>2</td>\n",
       "      <td>LE LOCLE LE CHALET</td>\n",
       "      <td>47.055918</td>\n",
       "      <td>6.738986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>3</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>47.057861</td>\n",
       "      <td>6.746153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001.000044.028:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>33249:1</td>\n",
       "      <td>0</td>\n",
       "      <td>LES BRENETS</td>\n",
       "      <td>47.067210</td>\n",
       "      <td>6.707389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991431</th>\n",
       "      <td>96814.000011.101:96814</td>\n",
       "      <td>TER 96814</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>23295:1</td>\n",
       "      <td>1</td>\n",
       "      <td>BELLEGARDE (AIN)</td>\n",
       "      <td>46.110918</td>\n",
       "      <td>5.825962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991432</th>\n",
       "      <td>96814.000011.101:96814</td>\n",
       "      <td>TER 96814</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>23295:1</td>\n",
       "      <td>2</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>45.760564</td>\n",
       "      <td>4.859990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991433</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>23296:1</td>\n",
       "      <td>0</td>\n",
       "      <td>GENEVE</td>\n",
       "      <td>46.210213</td>\n",
       "      <td>6.142452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991434</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>23296:1</td>\n",
       "      <td>1</td>\n",
       "      <td>BELLEGARDE (AIN)</td>\n",
       "      <td>46.110918</td>\n",
       "      <td>5.825962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991435</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>23296:1</td>\n",
       "      <td>2</td>\n",
       "      <td>LYON PART DIEU</td>\n",
       "      <td>45.760564</td>\n",
       "      <td>4.859990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991436 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      route_id route_long_name   trip_headsign  trip_id  \\\n",
       "0           00001.000044.018:1             R 1        LE LOCLE  33248:1   \n",
       "1           00001.000044.018:1             R 1        LE LOCLE  33248:1   \n",
       "2           00001.000044.018:1             R 1        LE LOCLE  33248:1   \n",
       "3           00001.000044.018:1             R 1        LE LOCLE  33248:1   \n",
       "4           00001.000044.028:1             R 1        LE LOCLE  33249:1   \n",
       "...                        ...             ...             ...      ...   \n",
       "991431  96814.000011.101:96814       TER 96814  LYON PART DIEU  23295:1   \n",
       "991432  96814.000011.101:96814       TER 96814  LYON PART DIEU  23295:1   \n",
       "991433  96818.000011.101:96818       TER 96818  LYON PART DIEU  23296:1   \n",
       "991434  96818.000011.101:96818       TER 96818  LYON PART DIEU  23296:1   \n",
       "991435  96818.000011.101:96818       TER 96818  LYON PART DIEU  23296:1   \n",
       "\n",
       "        stop_sequence           stop_name   stop_lat  stop_lon  \n",
       "0                   0         LES BRENETS  47.067210  6.707389  \n",
       "1                   1          LES FRETES  47.058580  6.725787  \n",
       "2                   2  LE LOCLE LE CHALET  47.055918  6.738986  \n",
       "3                   3            LE LOCLE  47.057861  6.746153  \n",
       "4                   0         LES BRENETS  47.067210  6.707389  \n",
       "...               ...                 ...        ...       ...  \n",
       "991431              1    BELLEGARDE (AIN)  46.110918  5.825962  \n",
       "991432              2      LYON PART DIEU  45.760564  4.859990  \n",
       "991433              0              GENEVE  46.210213  6.142452  \n",
       "991434              1    BELLEGARDE (AIN)  46.110918  5.825962  \n",
       "991435              2      LYON PART DIEU  45.760564  4.859990  \n",
       "\n",
       "[991436 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To create a route_sequence dataset that gives for each trip_id that belongs to a route the sequence of stations served'''\n",
    "route_sequence_Switzerland = trips_routes_stop_times_stops_Switzerland.groupby(['route_id','route_long_name','trip_headsign','trip_id','stop_sequence'], as_index=False)[['stop_name', 'stop_lat', 'stop_lon']].last()\n",
    "route_sequence_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2988642,
     "status": "ok",
     "timestamp": 1616025163497,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "GM9zfKNNkbEe",
    "outputId": "35ce71da-e67f-4d12-fffa-afe96eb5b323"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:16:00</td>\n",
       "      <td>18:16:00</td>\n",
       "      <td>8014554</td>\n",
       "      <td>0</td>\n",
       "      <td>ENGEN</td>\n",
       "      <td>47.856347</td>\n",
       "      <td>8.772786</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:28:00</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>8014534</td>\n",
       "      <td>1</td>\n",
       "      <td>IMMENDINGEN</td>\n",
       "      <td>47.936007</td>\n",
       "      <td>8.729536</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:40:00</td>\n",
       "      <td>18:40:00</td>\n",
       "      <td>8014529</td>\n",
       "      <td>2</td>\n",
       "      <td>DONAUESCHINGEN</td>\n",
       "      <td>47.947786</td>\n",
       "      <td>8.498919</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:49:00</td>\n",
       "      <td>18:50:00</td>\n",
       "      <td>8014521</td>\n",
       "      <td>3</td>\n",
       "      <td>VILLINGEN (SCHWARZW)</td>\n",
       "      <td>48.058022</td>\n",
       "      <td>8.465261</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>0:1</td>\n",
       "      <td>18:58:00</td>\n",
       "      <td>18:59:00</td>\n",
       "      <td>8014518</td>\n",
       "      <td>4</td>\n",
       "      <td>ST GEORGEN (SCHWARZW)</td>\n",
       "      <td>48.123813</td>\n",
       "      <td>8.341955</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">86913</th>\n",
       "      <th>7970</th>\n",
       "      <td>9:4</td>\n",
       "      <td>07:24:00</td>\n",
       "      <td>07:25:00</td>\n",
       "      <td>8014277</td>\n",
       "      <td>14</td>\n",
       "      <td>BADEN-BADEN</td>\n",
       "      <td>48.790327</td>\n",
       "      <td>8.190831</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8657</th>\n",
       "      <td>9:4</td>\n",
       "      <td>07:31:00</td>\n",
       "      <td>07:32:00</td>\n",
       "      <td>8014245</td>\n",
       "      <td>15</td>\n",
       "      <td>RASTATT</td>\n",
       "      <td>48.860483</td>\n",
       "      <td>8.215623</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10637</th>\n",
       "      <td>9:4</td>\n",
       "      <td>07:35:00</td>\n",
       "      <td>07:35:00</td>\n",
       "      <td>8014241</td>\n",
       "      <td>16</td>\n",
       "      <td>MUGGENSTURM</td>\n",
       "      <td>48.876805</td>\n",
       "      <td>8.274293</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10705</th>\n",
       "      <td>9:4</td>\n",
       "      <td>07:38:00</td>\n",
       "      <td>07:39:00</td>\n",
       "      <td>8014240</td>\n",
       "      <td>17</td>\n",
       "      <td>MALSCH</td>\n",
       "      <td>48.889506</td>\n",
       "      <td>8.323585</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9336</th>\n",
       "      <td>9:4</td>\n",
       "      <td>07:50:00</td>\n",
       "      <td>07:50:00</td>\n",
       "      <td>8014228</td>\n",
       "      <td>18</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>48.993515</td>\n",
       "      <td>8.402181</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991436 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            trip_id arrival_time departure_time  stop_id  stop_sequence  \\\n",
       "0     0         0:1     18:16:00       18:16:00  8014554              0   \n",
       "      541       0:1     18:28:00       18:30:00  8014534              1   \n",
       "      1100      0:1     18:40:00       18:40:00  8014529              2   \n",
       "      1895      0:1     18:49:00       18:50:00  8014521              3   \n",
       "      2592      0:1     18:58:00       18:59:00  8014518              4   \n",
       "...             ...          ...            ...      ...            ...   \n",
       "86913 7970      9:4     07:24:00       07:25:00  8014277             14   \n",
       "      8657      9:4     07:31:00       07:32:00  8014245             15   \n",
       "      10637     9:4     07:35:00       07:35:00  8014241             16   \n",
       "      10705     9:4     07:38:00       07:39:00  8014240             17   \n",
       "      9336      9:4     07:50:00       07:50:00  8014228             18   \n",
       "\n",
       "                         stop_name   stop_lat  stop_lon  country  \n",
       "0     0                      ENGEN  47.856347  8.772786  Germany  \n",
       "      541              IMMENDINGEN  47.936007  8.729536  Germany  \n",
       "      1100          DONAUESCHINGEN  47.947786  8.498919  Germany  \n",
       "      1895    VILLINGEN (SCHWARZW)  48.058022  8.465261  Germany  \n",
       "      2592   ST GEORGEN (SCHWARZW)  48.123813  8.341955  Germany  \n",
       "...                            ...        ...       ...      ...  \n",
       "86913 7970             BADEN-BADEN  48.790327  8.190831  Germany  \n",
       "      8657                 RASTATT  48.860483  8.215623  Germany  \n",
       "      10637            MUGGENSTURM  48.876805  8.274293  Germany  \n",
       "      10705                 MALSCH  48.889506  8.323585  Germany  \n",
       "      9336           KARLSRUHE HBF  48.993515  8.402181  Germany  \n",
       "\n",
       "[991436 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To groupby the trip_id and to order the stop_sequence in an ascending order (the stop_sequences of some\n",
    "routes are initially in descending order while other stop_sequences are in ascending order) '''\n",
    "\n",
    "trips_stop_sequence_ascending_Switzerland = stop_times_stops_Switzerland.groupby(['trip_id'], as_index=False).apply(lambda x: x.sort_values('stop_sequence'))\n",
    "trips_stop_sequence_ascending_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2993272,
     "status": "ok",
     "timestamp": 1616025168137,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "Rb6kwoG9kfn5",
    "outputId": "2cb94a71-b2c8-41af-ee0a-8c192b17f80d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:1</td>\n",
       "      <td>[ENGEN, IMMENDINGEN, DONAUESCHINGEN, VILLINGEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000:1</td>\n",
       "      <td>[ROMANSHORN, AMRISWIL, WEINFELDEN, FRAUENFELD,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001:1</td>\n",
       "      <td>[ZURICH HB, OLTEN, BAHN-2000-STRECKE, BERN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002:1</td>\n",
       "      <td>[ROMANSHORN, AMRISWIL, WEINFELDEN, FRAUENFELD,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003:1</td>\n",
       "      <td>[ROMANSHORN, AMRISWIL, WEINFELDEN, FRAUENFELD,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86909</th>\n",
       "      <td>99:1</td>\n",
       "      <td>[KARLSRUHE HBF, RASTATT, BADEN-BADEN, BUHL (BA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86910</th>\n",
       "      <td>9:1</td>\n",
       "      <td>[VILLINGEN (SCHWARZW), ST GEORGEN (SCHWARZW), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86911</th>\n",
       "      <td>9:2</td>\n",
       "      <td>[VILLINGEN (SCHWARZW), ST GEORGEN (SCHWARZW), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86912</th>\n",
       "      <td>9:3</td>\n",
       "      <td>[VILLINGEN (SCHWARZW), ST GEORGEN (SCHWARZW), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86913</th>\n",
       "      <td>9:4</td>\n",
       "      <td>[VILLINGEN (SCHWARZW), ST GEORGEN (SCHWARZW), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       trip_id                                      stop_sequence\n",
       "0          0:1  [ENGEN, IMMENDINGEN, DONAUESCHINGEN, VILLINGEN...\n",
       "1      10000:1  [ROMANSHORN, AMRISWIL, WEINFELDEN, FRAUENFELD,...\n",
       "2      10001:1        [ZURICH HB, OLTEN, BAHN-2000-STRECKE, BERN]\n",
       "3      10002:1  [ROMANSHORN, AMRISWIL, WEINFELDEN, FRAUENFELD,...\n",
       "4      10003:1  [ROMANSHORN, AMRISWIL, WEINFELDEN, FRAUENFELD,...\n",
       "...        ...                                                ...\n",
       "86909     99:1  [KARLSRUHE HBF, RASTATT, BADEN-BADEN, BUHL (BA...\n",
       "86910      9:1  [VILLINGEN (SCHWARZW), ST GEORGEN (SCHWARZW), ...\n",
       "86911      9:2  [VILLINGEN (SCHWARZW), ST GEORGEN (SCHWARZW), ...\n",
       "86912      9:3  [VILLINGEN (SCHWARZW), ST GEORGEN (SCHWARZW), ...\n",
       "86913      9:4  [VILLINGEN (SCHWARZW), ST GEORGEN (SCHWARZW), ...\n",
       "\n",
       "[86914 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To put the stop_names of a stop sequence of a trip_id in a list '''\n",
    "trips_stop_sequence_Switzerland = trips_stop_sequence_ascending_Switzerland.groupby('trip_id')['stop_name'].apply(lambda group_series: group_series.tolist()).reset_index()\n",
    "trips_stop_sequence_Switzerland.rename(columns={'stop_name':'stop_sequence'}, inplace=True)\n",
    "trips_stop_sequence_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To calculate the hash value for the stop sequence of each trip_id'''\n",
    "\n",
    "#To copy the filtered_trips dataset\n",
    "trips_hash_Switzerland = trips_stop_sequence_Switzerland.copy()\n",
    "\n",
    "#calculates the hash of the stop sequence in both order (ascending and descending)\n",
    "trips_hash_Switzerland['hash'] = trips_hash_Switzerland['stop_sequence'].apply(lambda x: hash(tuple(x)))\n",
    "trips_hash_Switzerland['hash_inverse'] = trips_hash_Switzerland['stop_sequence'].apply(lambda x: hash(tuple(x[::-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 2993270,
     "status": "ok",
     "timestamp": 1616025168146,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "pSMRFHRUkhSQ",
    "outputId": "861c98b0-84d7-470b-f830-8dbba17d0c6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>hash</th>\n",
       "      <th>hash_inverse</th>\n",
       "      <th>stop_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04236.06____.020:4236</td>\n",
       "      <td>RE 4236</td>\n",
       "      <td>19311</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>0:1</td>\n",
       "      <td>9205176474328118748</td>\n",
       "      <td>-2877522756731758300</td>\n",
       "      <td>[ENGEN, IMMENDINGEN, DONAUESCHINGEN, VILLINGEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>133763</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>1:1</td>\n",
       "      <td>-4850981020070306687</td>\n",
       "      <td>339185184194859384</td>\n",
       "      <td>[OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>1</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>1:2</td>\n",
       "      <td>-4850981020070306687</td>\n",
       "      <td>339185184194859384</td>\n",
       "      <td>[OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>13336</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>1:3</td>\n",
       "      <td>-4850981020070306687</td>\n",
       "      <td>339185184194859384</td>\n",
       "      <td>[OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>2610</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>1:4</td>\n",
       "      <td>-4850981020070306687</td>\n",
       "      <td>339185184194859384</td>\n",
       "      <td>[OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86909</th>\n",
       "      <td>87947.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>2364</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>49348:1</td>\n",
       "      <td>7350775758517724160</td>\n",
       "      <td>-998733850491266350</td>\n",
       "      <td>[LORRACH HBF, LORRACH MUSEUM/BURGHOF, LORRACH-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86910</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>56518</td>\n",
       "      <td>LORRACH HBF</td>\n",
       "      <td>49349:1</td>\n",
       "      <td>-998733850491266350</td>\n",
       "      <td>7350775758517724160</td>\n",
       "      <td>[WEIL AM RHEIN, WEIL AM RHEIN GARTENSTADT, WEI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86911</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>17102</td>\n",
       "      <td>ZELL (WIESENTAL)</td>\n",
       "      <td>49349:2</td>\n",
       "      <td>5974864185153478306</td>\n",
       "      <td>-438996269003196970</td>\n",
       "      <td>[WEIL AM RHEIN, WEIL AM RHEIN GARTENSTADT, WEI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86912</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>17102</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>49350:1</td>\n",
       "      <td>-438996269003196970</td>\n",
       "      <td>5974864185153478306</td>\n",
       "      <td>[ZELL (WIESENTAL), HAUSEN-RAITBACH, FAHRNAU, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86913</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>56518</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>49350:2</td>\n",
       "      <td>7350775758517724160</td>\n",
       "      <td>-998733850491266350</td>\n",
       "      <td>[LORRACH HBF, LORRACH MUSEUM/BURGHOF, LORRACH-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    route_id route_long_name  service_id     trip_headsign  \\\n",
       "0      04236.06____.020:4236         RE 4236       19311     KARLSRUHE HBF   \n",
       "1      04700.06____.001:4700         RE 4700      133763     KARLSRUHE HBF   \n",
       "2      04700.06____.001:4700         RE 4700           1     KARLSRUHE HBF   \n",
       "3      04700.06____.001:4700         RE 4700       13336     KARLSRUHE HBF   \n",
       "4      04700.06____.001:4700         RE 4700        2610     KARLSRUHE HBF   \n",
       "...                      ...             ...         ...               ...   \n",
       "86909     87947.L7____.001:5             S 5        2364     WEIL AM RHEIN   \n",
       "86910     87948.L7____.001:5             S 5       56518       LORRACH HBF   \n",
       "86911     87948.L7____.001:5             S 5       17102  ZELL (WIESENTAL)   \n",
       "86912     87949.L7____.001:5             S 5       17102     WEIL AM RHEIN   \n",
       "86913     87949.L7____.001:5             S 5       56518     WEIL AM RHEIN   \n",
       "\n",
       "       trip_id                 hash         hash_inverse  \\\n",
       "0          0:1  9205176474328118748 -2877522756731758300   \n",
       "1          1:1 -4850981020070306687   339185184194859384   \n",
       "2          1:2 -4850981020070306687   339185184194859384   \n",
       "3          1:3 -4850981020070306687   339185184194859384   \n",
       "4          1:4 -4850981020070306687   339185184194859384   \n",
       "...        ...                  ...                  ...   \n",
       "86909  49348:1  7350775758517724160  -998733850491266350   \n",
       "86910  49349:1  -998733850491266350  7350775758517724160   \n",
       "86911  49349:2  5974864185153478306  -438996269003196970   \n",
       "86912  49350:1  -438996269003196970  5974864185153478306   \n",
       "86913  49350:2  7350775758517724160  -998733850491266350   \n",
       "\n",
       "                                           stop_sequence  \n",
       "0      [ENGEN, IMMENDINGEN, DONAUESCHINGEN, VILLINGEN...  \n",
       "1      [OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...  \n",
       "2      [OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...  \n",
       "3      [OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...  \n",
       "4      [OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...  \n",
       "...                                                  ...  \n",
       "86909  [LORRACH HBF, LORRACH MUSEUM/BURGHOF, LORRACH-...  \n",
       "86910  [WEIL AM RHEIN, WEIL AM RHEIN GARTENSTADT, WEI...  \n",
       "86911  [WEIL AM RHEIN, WEIL AM RHEIN GARTENSTADT, WEI...  \n",
       "86912  [ZELL (WIESENTAL), HAUSEN-RAITBACH, FAHRNAU, S...  \n",
       "86913  [LORRACH HBF, LORRACH MUSEUM/BURGHOF, LORRACH-...  \n",
       "\n",
       "[86914 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To add the list of stop_sequence of stations to the trips_hash_Switzerland df by joining on trip_id'''\n",
    "# To add the stop_sequence of stations to the trips_routes_Swizerland df by joining on trip_id\n",
    "trips_hash_stop_sequence_Switzerland = pd.merge(trips_routes_Switzerland, trips_hash_Switzerland, on='trip_id', how='left')\n",
    "\n",
    "# To put the columns in a more logical order\n",
    "trips_hash_stop_sequence_Switzerland = trips_hash_stop_sequence_Switzerland[['route_id', 'route_long_name','service_id','trip_headsign','trip_id','hash', 'hash_inverse','stop_sequence']]\n",
    "trips_hash_stop_sequence_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>hash</th>\n",
       "      <th>hash_inverse</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>departure_time_first</th>\n",
       "      <th>departure_time_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04236.06____.020:4236</td>\n",
       "      <td>RE 4236</td>\n",
       "      <td>19311</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>0:1</td>\n",
       "      <td>9205176474328118748</td>\n",
       "      <td>-2877522756731758300</td>\n",
       "      <td>[ENGEN, IMMENDINGEN, DONAUESCHINGEN, VILLINGEN...</td>\n",
       "      <td>18:16:00</td>\n",
       "      <td>20:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>133763</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>1:1</td>\n",
       "      <td>-4850981020070306687</td>\n",
       "      <td>339185184194859384</td>\n",
       "      <td>[OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...</td>\n",
       "      <td>04:47:00</td>\n",
       "      <td>05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>1</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>1:2</td>\n",
       "      <td>-4850981020070306687</td>\n",
       "      <td>339185184194859384</td>\n",
       "      <td>[OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...</td>\n",
       "      <td>04:47:00</td>\n",
       "      <td>05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>13336</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>1:3</td>\n",
       "      <td>-4850981020070306687</td>\n",
       "      <td>339185184194859384</td>\n",
       "      <td>[OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...</td>\n",
       "      <td>04:47:00</td>\n",
       "      <td>05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04700.06____.001:4700</td>\n",
       "      <td>RE 4700</td>\n",
       "      <td>2610</td>\n",
       "      <td>KARLSRUHE HBF</td>\n",
       "      <td>1:4</td>\n",
       "      <td>-4850981020070306687</td>\n",
       "      <td>339185184194859384</td>\n",
       "      <td>[OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...</td>\n",
       "      <td>04:47:00</td>\n",
       "      <td>05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86909</th>\n",
       "      <td>87947.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>2364</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>49348:1</td>\n",
       "      <td>7350775758517724160</td>\n",
       "      <td>-998733850491266350</td>\n",
       "      <td>[LORRACH HBF, LORRACH MUSEUM/BURGHOF, LORRACH-...</td>\n",
       "      <td>09:34:00</td>\n",
       "      <td>09:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86910</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>56518</td>\n",
       "      <td>LORRACH HBF</td>\n",
       "      <td>49349:1</td>\n",
       "      <td>-998733850491266350</td>\n",
       "      <td>7350775758517724160</td>\n",
       "      <td>[WEIL AM RHEIN, WEIL AM RHEIN GARTENSTADT, WEI...</td>\n",
       "      <td>09:14:00</td>\n",
       "      <td>09:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86911</th>\n",
       "      <td>87948.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>17102</td>\n",
       "      <td>ZELL (WIESENTAL)</td>\n",
       "      <td>49349:2</td>\n",
       "      <td>5974864185153478306</td>\n",
       "      <td>-438996269003196970</td>\n",
       "      <td>[WEIL AM RHEIN, WEIL AM RHEIN GARTENSTADT, WEI...</td>\n",
       "      <td>09:14:00</td>\n",
       "      <td>09:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86912</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>17102</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>49350:1</td>\n",
       "      <td>-438996269003196970</td>\n",
       "      <td>5974864185153478306</td>\n",
       "      <td>[ZELL (WIESENTAL), HAUSEN-RAITBACH, FAHRNAU, S...</td>\n",
       "      <td>10:04:00</td>\n",
       "      <td>10:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86913</th>\n",
       "      <td>87949.L7____.001:5</td>\n",
       "      <td>S 5</td>\n",
       "      <td>56518</td>\n",
       "      <td>WEIL AM RHEIN</td>\n",
       "      <td>49350:2</td>\n",
       "      <td>7350775758517724160</td>\n",
       "      <td>-998733850491266350</td>\n",
       "      <td>[LORRACH HBF, LORRACH MUSEUM/BURGHOF, LORRACH-...</td>\n",
       "      <td>10:34:00</td>\n",
       "      <td>10:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    route_id route_long_name  service_id     trip_headsign  \\\n",
       "0      04236.06____.020:4236         RE 4236       19311     KARLSRUHE HBF   \n",
       "1      04700.06____.001:4700         RE 4700      133763     KARLSRUHE HBF   \n",
       "2      04700.06____.001:4700         RE 4700           1     KARLSRUHE HBF   \n",
       "3      04700.06____.001:4700         RE 4700       13336     KARLSRUHE HBF   \n",
       "4      04700.06____.001:4700         RE 4700        2610     KARLSRUHE HBF   \n",
       "...                      ...             ...         ...               ...   \n",
       "86909     87947.L7____.001:5             S 5        2364     WEIL AM RHEIN   \n",
       "86910     87948.L7____.001:5             S 5       56518       LORRACH HBF   \n",
       "86911     87948.L7____.001:5             S 5       17102  ZELL (WIESENTAL)   \n",
       "86912     87949.L7____.001:5             S 5       17102     WEIL AM RHEIN   \n",
       "86913     87949.L7____.001:5             S 5       56518     WEIL AM RHEIN   \n",
       "\n",
       "       trip_id                 hash         hash_inverse  \\\n",
       "0          0:1  9205176474328118748 -2877522756731758300   \n",
       "1          1:1 -4850981020070306687   339185184194859384   \n",
       "2          1:2 -4850981020070306687   339185184194859384   \n",
       "3          1:3 -4850981020070306687   339185184194859384   \n",
       "4          1:4 -4850981020070306687   339185184194859384   \n",
       "...        ...                  ...                  ...   \n",
       "86909  49348:1  7350775758517724160  -998733850491266350   \n",
       "86910  49349:1  -998733850491266350  7350775758517724160   \n",
       "86911  49349:2  5974864185153478306  -438996269003196970   \n",
       "86912  49350:1  -438996269003196970  5974864185153478306   \n",
       "86913  49350:2  7350775758517724160  -998733850491266350   \n",
       "\n",
       "                                           stop_sequence departure_time_first  \\\n",
       "0      [ENGEN, IMMENDINGEN, DONAUESCHINGEN, VILLINGEN...             18:16:00   \n",
       "1      [OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...             04:47:00   \n",
       "2      [OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...             04:47:00   \n",
       "3      [OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...             04:47:00   \n",
       "4      [OFFENBURG, APPENWEIER, RENCHEN (D), ACHERN, B...             04:47:00   \n",
       "...                                                  ...                  ...   \n",
       "86909  [LORRACH HBF, LORRACH MUSEUM/BURGHOF, LORRACH-...             09:34:00   \n",
       "86910  [WEIL AM RHEIN, WEIL AM RHEIN GARTENSTADT, WEI...             09:14:00   \n",
       "86911  [WEIL AM RHEIN, WEIL AM RHEIN GARTENSTADT, WEI...             09:14:00   \n",
       "86912  [ZELL (WIESENTAL), HAUSEN-RAITBACH, FAHRNAU, S...             10:04:00   \n",
       "86913  [LORRACH HBF, LORRACH MUSEUM/BURGHOF, LORRACH-...             10:34:00   \n",
       "\n",
       "      departure_time_last  \n",
       "0                20:49:00  \n",
       "1                05:40:00  \n",
       "2                05:40:00  \n",
       "3                05:40:00  \n",
       "4                05:40:00  \n",
       "...                   ...  \n",
       "86909            09:45:00  \n",
       "86910            09:28:00  \n",
       "86911            09:56:00  \n",
       "86912            10:45:00  \n",
       "86913            10:45:00  \n",
       "\n",
       "[86914 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Merges the trips_hash_stop_sequence with the departure_times'''\n",
    "trips_hash_stop_sequence_departure_Switzerland = trips_hash_stop_sequence_Switzerland.merge(departure_times_Switzerland[['trip_id','departure_time_first','departure_time_last']], on='trip_id')\n",
    "trips_hash_stop_sequence_departure_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2993266,
     "status": "ok",
     "timestamp": 1616025168150,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "jJwKsukGki30",
    "outputId": "5da75bba-a298-4c5a-dea3-dabbfe00002d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>count_service_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13936</th>\n",
       "      <td>244127</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13937</th>\n",
       "      <td>244129</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>254888</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13939</th>\n",
       "      <td>254889</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13940</th>\n",
       "      <td>255046</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13941 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       service_id  count_service_id\n",
       "0               1                90\n",
       "1               2                31\n",
       "2               5                83\n",
       "3               6                83\n",
       "4               8                 5\n",
       "...           ...               ...\n",
       "13936      244127                88\n",
       "13937      244129                34\n",
       "13938      254888                67\n",
       "13939      254889               120\n",
       "13940      255046                25\n",
       "\n",
       "[13941 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To count the number of dates for each service_id '''\n",
    "service_id_df_Switzerland = filtered_calendar_dates_Switzerland.groupby(['service_id'])[['service_id']].count().rename(columns={'service_id':'count_service_id'}).reset_index()\n",
    "service_id_df_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2993993,
     "status": "ok",
     "timestamp": 1616025168886,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "vRUDY0oGkkyQ",
    "outputId": "1a10a4d5-5ae1-4023-a958-f231e9953724"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>dates</th>\n",
       "      <th>count_service_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{20210315, 20210316, 20210317, 20210318, 20210...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{20210701, 20210702, 20210703, 20210704, 20210...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>{20210626, 20210627, 20210613, 20210619, 20210...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13936</th>\n",
       "      <td>244127</td>\n",
       "      <td>{20210701, 20210704, 20210705, 20210706, 20210...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13937</th>\n",
       "      <td>244129</td>\n",
       "      <td>{20210702, 20210319, 20210320, 20210703, 20210...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>254888</td>\n",
       "      <td>{20210701, 20210702, 20210703, 20210704, 20210...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13939</th>\n",
       "      <td>254889</td>\n",
       "      <td>{20210701, 20210702, 20210703, 20210704, 20210...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13940</th>\n",
       "      <td>255046</td>\n",
       "      <td>{20210501, 20210503, 20210504, 20210505, 20210...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13941 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       service_id                                              dates  \\\n",
       "0               1  {20210315, 20210316, 20210317, 20210318, 20210...   \n",
       "1               2  {20210701, 20210702, 20210703, 20210704, 20210...   \n",
       "2               5  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "3               6  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "4               8  {20210626, 20210627, 20210613, 20210619, 20210...   \n",
       "...           ...                                                ...   \n",
       "13936      244127  {20210701, 20210704, 20210705, 20210706, 20210...   \n",
       "13937      244129  {20210702, 20210319, 20210320, 20210703, 20210...   \n",
       "13938      254888  {20210701, 20210702, 20210703, 20210704, 20210...   \n",
       "13939      254889  {20210701, 20210702, 20210703, 20210704, 20210...   \n",
       "13940      255046  {20210501, 20210503, 20210504, 20210505, 20210...   \n",
       "\n",
       "       count_service_id  \n",
       "0                    90  \n",
       "1                    31  \n",
       "2                    83  \n",
       "3                    83  \n",
       "4                     5  \n",
       "...                 ...  \n",
       "13936                88  \n",
       "13937                34  \n",
       "13938                67  \n",
       "13939               120  \n",
       "13940                25  \n",
       "\n",
       "[13941 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To regroup the days per service_id in a set '''\n",
    "service_id_dates_Switzerland = filtered_calendar_dates_Switzerland.groupby('service_id')['date'].apply(lambda group_series: set(group_series.tolist())).reset_index()\n",
    "service_id_dates_Switzerland.rename(columns={'date':'dates'}, inplace=True)\n",
    "service_id_dates_Switzerland = service_id_dates_Switzerland.merge(service_id_df_Switzerland, on='service_id', how='left')\n",
    "service_id_dates_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>country</th>\n",
       "      <th>dates</th>\n",
       "      <th>count_service_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>936</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>8504392</td>\n",
       "      <td>0</td>\n",
       "      <td>LES BRENETS</td>\n",
       "      <td>47.067210</td>\n",
       "      <td>6.707389</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>936</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>05:53:00</td>\n",
       "      <td>05:54:00</td>\n",
       "      <td>8504391</td>\n",
       "      <td>1</td>\n",
       "      <td>LES FRETES</td>\n",
       "      <td>47.058580</td>\n",
       "      <td>6.725787</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>936</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>05:54:00</td>\n",
       "      <td>05:55:00</td>\n",
       "      <td>8530260</td>\n",
       "      <td>2</td>\n",
       "      <td>LE LOCLE LE CHALET</td>\n",
       "      <td>47.055918</td>\n",
       "      <td>6.738986</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>936</td>\n",
       "      <td>33248:1</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>R</td>\n",
       "      <td>R 1</td>\n",
       "      <td>05:58:00</td>\n",
       "      <td>05:58:00</td>\n",
       "      <td>8504316</td>\n",
       "      <td>3</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>47.057861</td>\n",
       "      <td>6.746153</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002.000044.017:2</td>\n",
       "      <td>936</td>\n",
       "      <td>33250:1</td>\n",
       "      <td>LES BRENETS</td>\n",
       "      <td>R</td>\n",
       "      <td>R 2</td>\n",
       "      <td>06:01:00</td>\n",
       "      <td>06:01:00</td>\n",
       "      <td>8504316</td>\n",
       "      <td>0</td>\n",
       "      <td>LE LOCLE</td>\n",
       "      <td>47.057861</td>\n",
       "      <td>6.746153</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650517</th>\n",
       "      <td>96765.000011.101:L6</td>\n",
       "      <td>117674</td>\n",
       "      <td>23267:1</td>\n",
       "      <td>GENEVE</td>\n",
       "      <td>S</td>\n",
       "      <td>L6</td>\n",
       "      <td>21:50:00</td>\n",
       "      <td>21:50:00</td>\n",
       "      <td>8501006</td>\n",
       "      <td>4</td>\n",
       "      <td>MEYRIN</td>\n",
       "      <td>46.222335</td>\n",
       "      <td>6.076900</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>{20210315, 20210316, 20210317, 20210318, 20210...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650518</th>\n",
       "      <td>96765.000011.101:L6</td>\n",
       "      <td>117674</td>\n",
       "      <td>23267:1</td>\n",
       "      <td>GENEVE</td>\n",
       "      <td>S</td>\n",
       "      <td>L6</td>\n",
       "      <td>21:54:00</td>\n",
       "      <td>21:55:00</td>\n",
       "      <td>8501007</td>\n",
       "      <td>5</td>\n",
       "      <td>VERNIER</td>\n",
       "      <td>46.220719</td>\n",
       "      <td>6.093891</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>{20210315, 20210316, 20210317, 20210318, 20210...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650519</th>\n",
       "      <td>96765.000011.101:L6</td>\n",
       "      <td>117674</td>\n",
       "      <td>23267:1</td>\n",
       "      <td>GENEVE</td>\n",
       "      <td>S</td>\n",
       "      <td>L6</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>8501008</td>\n",
       "      <td>6</td>\n",
       "      <td>GENEVE</td>\n",
       "      <td>46.210213</td>\n",
       "      <td>6.142452</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>{20210315, 20210316, 20210317, 20210318, 20210...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650520</th>\n",
       "      <td>96785.87_LEX.001:L6</td>\n",
       "      <td>65904</td>\n",
       "      <td>47667:1</td>\n",
       "      <td>POUGNY-CHANCY</td>\n",
       "      <td>TER</td>\n",
       "      <td>L6</td>\n",
       "      <td>19:37:00</td>\n",
       "      <td>19:37:00</td>\n",
       "      <td>8774500</td>\n",
       "      <td>0</td>\n",
       "      <td>BELLEGARDE (AIN)</td>\n",
       "      <td>46.110918</td>\n",
       "      <td>5.825962</td>\n",
       "      <td>France</td>\n",
       "      <td>{20210412, 20210413, 20210414, 20210415, 20210...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650521</th>\n",
       "      <td>96785.87_LEX.001:L6</td>\n",
       "      <td>65904</td>\n",
       "      <td>47667:1</td>\n",
       "      <td>POUGNY-CHANCY</td>\n",
       "      <td>TER</td>\n",
       "      <td>L6</td>\n",
       "      <td>19:47:00</td>\n",
       "      <td>19:47:00</td>\n",
       "      <td>8774538</td>\n",
       "      <td>1</td>\n",
       "      <td>POUGNY-CHANCY</td>\n",
       "      <td>46.144737</td>\n",
       "      <td>5.961185</td>\n",
       "      <td>France</td>\n",
       "      <td>{20210412, 20210413, 20210414, 20210415, 20210...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650522 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   route_id  service_id  trip_id  trip_headsign  \\\n",
       "0        00001.000044.018:1         936  33248:1       LE LOCLE   \n",
       "1        00001.000044.018:1         936  33248:1       LE LOCLE   \n",
       "2        00001.000044.018:1         936  33248:1       LE LOCLE   \n",
       "3        00001.000044.018:1         936  33248:1       LE LOCLE   \n",
       "4        00002.000044.017:2         936  33250:1    LES BRENETS   \n",
       "...                     ...         ...      ...            ...   \n",
       "650517  96765.000011.101:L6      117674  23267:1         GENEVE   \n",
       "650518  96765.000011.101:L6      117674  23267:1         GENEVE   \n",
       "650519  96765.000011.101:L6      117674  23267:1         GENEVE   \n",
       "650520  96785.87_LEX.001:L6       65904  47667:1  POUGNY-CHANCY   \n",
       "650521  96785.87_LEX.001:L6       65904  47667:1  POUGNY-CHANCY   \n",
       "\n",
       "       route_short_name route_long_name arrival_time departure_time  stop_id  \\\n",
       "0                     R             R 1     05:50:00       05:50:00  8504392   \n",
       "1                     R             R 1     05:53:00       05:54:00  8504391   \n",
       "2                     R             R 1     05:54:00       05:55:00  8530260   \n",
       "3                     R             R 1     05:58:00       05:58:00  8504316   \n",
       "4                     R             R 2     06:01:00       06:01:00  8504316   \n",
       "...                 ...             ...          ...            ...      ...   \n",
       "650517                S              L6     21:50:00       21:50:00  8501006   \n",
       "650518                S              L6     21:54:00       21:55:00  8501007   \n",
       "650519                S              L6     22:00:00       22:00:00  8501008   \n",
       "650520              TER              L6     19:37:00       19:37:00  8774500   \n",
       "650521              TER              L6     19:47:00       19:47:00  8774538   \n",
       "\n",
       "        stop_sequence           stop_name   stop_lat  stop_lon      country  \\\n",
       "0                   0         LES BRENETS  47.067210  6.707389  Switzerland   \n",
       "1                   1          LES FRETES  47.058580  6.725787  Switzerland   \n",
       "2                   2  LE LOCLE LE CHALET  47.055918  6.738986  Switzerland   \n",
       "3                   3            LE LOCLE  47.057861  6.746153  Switzerland   \n",
       "4                   0            LE LOCLE  47.057861  6.746153  Switzerland   \n",
       "...               ...                 ...        ...       ...          ...   \n",
       "650517              4              MEYRIN  46.222335  6.076900  Switzerland   \n",
       "650518              5             VERNIER  46.220719  6.093891  Switzerland   \n",
       "650519              6              GENEVE  46.210213  6.142452  Switzerland   \n",
       "650520              0    BELLEGARDE (AIN)  46.110918  5.825962       France   \n",
       "650521              1       POUGNY-CHANCY  46.144737  5.961185       France   \n",
       "\n",
       "                                                    dates  count_service_id  \n",
       "0       {20210701, 20210702, 20210705, 20210706, 20210...                83  \n",
       "1       {20210701, 20210702, 20210705, 20210706, 20210...                83  \n",
       "2       {20210701, 20210702, 20210705, 20210706, 20210...                83  \n",
       "3       {20210701, 20210702, 20210705, 20210706, 20210...                83  \n",
       "4       {20210701, 20210702, 20210705, 20210706, 20210...                83  \n",
       "...                                                   ...               ...  \n",
       "650517  {20210315, 20210316, 20210317, 20210318, 20210...                68  \n",
       "650518  {20210315, 20210316, 20210317, 20210318, 20210...                68  \n",
       "650519  {20210315, 20210316, 20210317, 20210318, 20210...                68  \n",
       "650520  {20210412, 20210413, 20210414, 20210415, 20210...                 7  \n",
       "650521  {20210412, 20210413, 20210414, 20210415, 20210...                 7  \n",
       "\n",
       "[650522 rows x 16 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To merge the trips_hash_stop_sequence df with the service_id_dates to get the sets of corresponding dates'''\n",
    "trips_routes_stop_times_stops_dates_Switzerland = pd.merge(trips_routes_stop_times_stops_Switzerland, service_id_dates_Switzerland, on='service_id', how='inner')\n",
    "trips_routes_stop_times_stops_dates_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2996818,
     "status": "ok",
     "timestamp": 1616025171719,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "jjylZ1eukmuM",
    "outputId": "56b87371-5c43-4842-ca94-16d9e29d0ad8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>hash</th>\n",
       "      <th>hash_inverse</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>departure_time_first</th>\n",
       "      <th>departure_time_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>936</td>\n",
       "      <td>[33248:1]</td>\n",
       "      <td>[05:50:00]</td>\n",
       "      <td>[05:58:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.000044.028:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>869</td>\n",
       "      <td>[33249:1]</td>\n",
       "      <td>[06:08:00]</td>\n",
       "      <td>[06:16:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001.000104.001:1</td>\n",
       "      <td>CC 1</td>\n",
       "      <td>3865371173043443348</td>\n",
       "      <td>-6836560398534858013</td>\n",
       "      <td>5072</td>\n",
       "      <td>[4117:1]</td>\n",
       "      <td>[07:36:00]</td>\n",
       "      <td>[08:36:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002.000044.017:2</td>\n",
       "      <td>R 2</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>936</td>\n",
       "      <td>[33250:1]</td>\n",
       "      <td>[06:01:00]</td>\n",
       "      <td>[06:08:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002.000044.024:2</td>\n",
       "      <td>R 2</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>869</td>\n",
       "      <td>[33251:1]</td>\n",
       "      <td>[06:18:00]</td>\n",
       "      <td>[06:25:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86909</th>\n",
       "      <td>96806.000011.102:96806</td>\n",
       "      <td>TER 96806</td>\n",
       "      <td>1700149812652076650</td>\n",
       "      <td>256460250998497924</td>\n",
       "      <td>44307</td>\n",
       "      <td>[23292:1]</td>\n",
       "      <td>[18:39:00]</td>\n",
       "      <td>[20:59:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86910</th>\n",
       "      <td>96810.000011.101:96810</td>\n",
       "      <td>TER 96810</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>116609</td>\n",
       "      <td>[23293:1]</td>\n",
       "      <td>[06:16:00]</td>\n",
       "      <td>[08:24:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86911</th>\n",
       "      <td>96812.000011.101:96812</td>\n",
       "      <td>TER 96812</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>9453</td>\n",
       "      <td>[23294:1]</td>\n",
       "      <td>[07:17:00]</td>\n",
       "      <td>[09:25:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86912</th>\n",
       "      <td>96814.000011.101:96814</td>\n",
       "      <td>TER 96814</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>116609</td>\n",
       "      <td>[23295:1]</td>\n",
       "      <td>[12:25:00]</td>\n",
       "      <td>[14:33:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86913</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>44307</td>\n",
       "      <td>[23296:1]</td>\n",
       "      <td>[19:26:00]</td>\n",
       "      <td>[21:34:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     route_id route_long_name                 hash  \\\n",
       "0          00001.000044.018:1             R 1 -5189486139819647528   \n",
       "1          00001.000044.028:1             R 1 -5189486139819647528   \n",
       "2          00001.000104.001:1            CC 1  3865371173043443348   \n",
       "3          00002.000044.017:2             R 2  3242894917632905562   \n",
       "4          00002.000044.024:2             R 2  3242894917632905562   \n",
       "...                       ...             ...                  ...   \n",
       "86909  96806.000011.102:96806       TER 96806  1700149812652076650   \n",
       "86910  96810.000011.101:96810       TER 96810 -4684204956159847117   \n",
       "86911  96812.000011.101:96812       TER 96812 -4684204956159847117   \n",
       "86912  96814.000011.101:96814       TER 96814 -4684204956159847117   \n",
       "86913  96818.000011.101:96818       TER 96818 -4684204956159847117   \n",
       "\n",
       "              hash_inverse  service_id    trip_id departure_time_first  \\\n",
       "0      3242894917632905562         936  [33248:1]           [05:50:00]   \n",
       "1      3242894917632905562         869  [33249:1]           [06:08:00]   \n",
       "2     -6836560398534858013        5072   [4117:1]           [07:36:00]   \n",
       "3     -5189486139819647528         936  [33250:1]           [06:01:00]   \n",
       "4     -5189486139819647528         869  [33251:1]           [06:18:00]   \n",
       "...                    ...         ...        ...                  ...   \n",
       "86909   256460250998497924       44307  [23292:1]           [18:39:00]   \n",
       "86910 -1289879366665992573      116609  [23293:1]           [06:16:00]   \n",
       "86911 -1289879366665992573        9453  [23294:1]           [07:17:00]   \n",
       "86912 -1289879366665992573      116609  [23295:1]           [12:25:00]   \n",
       "86913 -1289879366665992573       44307  [23296:1]           [19:26:00]   \n",
       "\n",
       "      departure_time_last  \n",
       "0              [05:58:00]  \n",
       "1              [06:16:00]  \n",
       "2              [08:36:00]  \n",
       "3              [06:08:00]  \n",
       "4              [06:25:00]  \n",
       "...                   ...  \n",
       "86909          [20:59:00]  \n",
       "86910          [08:24:00]  \n",
       "86911          [09:25:00]  \n",
       "86912          [14:33:00]  \n",
       "86913          [21:34:00]  \n",
       "\n",
       "[86914 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To put the different trip_ids in a list after joining and add the departure_time first and last'''\n",
    "common_columns = ['route_id','route_long_name','hash', 'hash_inverse', 'service_id']\n",
    "route_hash_freq_Switzerland = trips_hash_stop_sequence_Switzerland.groupby(common_columns)['trip_id'].apply(lambda group_series: group_series.tolist()).reset_index()\n",
    "route_hash_freq_Switzerland_dep_first = trips_hash_stop_sequence_departure_Switzerland.groupby(common_columns)['departure_time_first'].apply(lambda group_series: group_series.tolist()).reset_index()\n",
    "route_hash_freq_Switzerland_dep_last = trips_hash_stop_sequence_departure_Switzerland.groupby(common_columns)['departure_time_last'].apply(lambda group_series: group_series.tolist()).reset_index()\n",
    "route_hash_freq_Switzerland = route_hash_freq_Switzerland.merge(route_hash_freq_Switzerland_dep_first, on= common_columns)\n",
    "route_hash_freq_Switzerland = route_hash_freq_Switzerland.merge(route_hash_freq_Switzerland_dep_last, on= common_columns)\n",
    "route_hash_freq_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2996809,
     "status": "ok",
     "timestamp": 1616025171720,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "brVANOIGkodz",
    "outputId": "b93faa87-1fb3-4ed6-cb84-7eeacaecd70b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>hash</th>\n",
       "      <th>hash_inverse</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>departure_time_first</th>\n",
       "      <th>departure_time_last</th>\n",
       "      <th>stop_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>936</td>\n",
       "      <td>[33248:1]</td>\n",
       "      <td>[05:50:00]</td>\n",
       "      <td>[05:58:00]</td>\n",
       "      <td>[LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.000044.028:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>869</td>\n",
       "      <td>[33249:1]</td>\n",
       "      <td>[06:08:00]</td>\n",
       "      <td>[06:16:00]</td>\n",
       "      <td>[LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001.000104.001:1</td>\n",
       "      <td>CC 1</td>\n",
       "      <td>3865371173043443348</td>\n",
       "      <td>-6836560398534858013</td>\n",
       "      <td>5072</td>\n",
       "      <td>[4117:1]</td>\n",
       "      <td>[07:36:00]</td>\n",
       "      <td>[08:36:00]</td>\n",
       "      <td>[BRIENZ BRB, PLANALP, BRIENZER ROTHORN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002.000044.017:2</td>\n",
       "      <td>R 2</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>936</td>\n",
       "      <td>[33250:1]</td>\n",
       "      <td>[06:01:00]</td>\n",
       "      <td>[06:08:00]</td>\n",
       "      <td>[LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002.000044.024:2</td>\n",
       "      <td>R 2</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>869</td>\n",
       "      <td>[33251:1]</td>\n",
       "      <td>[06:18:00]</td>\n",
       "      <td>[06:25:00]</td>\n",
       "      <td>[LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86909</th>\n",
       "      <td>96806.000011.102:96806</td>\n",
       "      <td>TER 96806</td>\n",
       "      <td>1700149812652076650</td>\n",
       "      <td>256460250998497924</td>\n",
       "      <td>44307</td>\n",
       "      <td>[23292:1]</td>\n",
       "      <td>[18:39:00]</td>\n",
       "      <td>[20:59:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), CULOZ, GRENOBLE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86910</th>\n",
       "      <td>96810.000011.101:96810</td>\n",
       "      <td>TER 96810</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>116609</td>\n",
       "      <td>[23293:1]</td>\n",
       "      <td>[06:16:00]</td>\n",
       "      <td>[08:24:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), LYON PART DIEU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86911</th>\n",
       "      <td>96812.000011.101:96812</td>\n",
       "      <td>TER 96812</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>9453</td>\n",
       "      <td>[23294:1]</td>\n",
       "      <td>[07:17:00]</td>\n",
       "      <td>[09:25:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), LYON PART DIEU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86912</th>\n",
       "      <td>96814.000011.101:96814</td>\n",
       "      <td>TER 96814</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>116609</td>\n",
       "      <td>[23295:1]</td>\n",
       "      <td>[12:25:00]</td>\n",
       "      <td>[14:33:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), LYON PART DIEU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86913</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>44307</td>\n",
       "      <td>[23296:1]</td>\n",
       "      <td>[19:26:00]</td>\n",
       "      <td>[21:34:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), LYON PART DIEU]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     route_id route_long_name                 hash  \\\n",
       "0          00001.000044.018:1             R 1 -5189486139819647528   \n",
       "1          00001.000044.028:1             R 1 -5189486139819647528   \n",
       "2          00001.000104.001:1            CC 1  3865371173043443348   \n",
       "3          00002.000044.017:2             R 2  3242894917632905562   \n",
       "4          00002.000044.024:2             R 2  3242894917632905562   \n",
       "...                       ...             ...                  ...   \n",
       "86909  96806.000011.102:96806       TER 96806  1700149812652076650   \n",
       "86910  96810.000011.101:96810       TER 96810 -4684204956159847117   \n",
       "86911  96812.000011.101:96812       TER 96812 -4684204956159847117   \n",
       "86912  96814.000011.101:96814       TER 96814 -4684204956159847117   \n",
       "86913  96818.000011.101:96818       TER 96818 -4684204956159847117   \n",
       "\n",
       "              hash_inverse  service_id    trip_id departure_time_first  \\\n",
       "0      3242894917632905562         936  [33248:1]           [05:50:00]   \n",
       "1      3242894917632905562         869  [33249:1]           [06:08:00]   \n",
       "2     -6836560398534858013        5072   [4117:1]           [07:36:00]   \n",
       "3     -5189486139819647528         936  [33250:1]           [06:01:00]   \n",
       "4     -5189486139819647528         869  [33251:1]           [06:18:00]   \n",
       "...                    ...         ...        ...                  ...   \n",
       "86909   256460250998497924       44307  [23292:1]           [18:39:00]   \n",
       "86910 -1289879366665992573      116609  [23293:1]           [06:16:00]   \n",
       "86911 -1289879366665992573        9453  [23294:1]           [07:17:00]   \n",
       "86912 -1289879366665992573      116609  [23295:1]           [12:25:00]   \n",
       "86913 -1289879366665992573       44307  [23296:1]           [19:26:00]   \n",
       "\n",
       "      departure_time_last                                      stop_sequence  \n",
       "0              [05:58:00]  [LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...  \n",
       "1              [06:16:00]  [LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...  \n",
       "2              [08:36:00]            [BRIENZ BRB, PLANALP, BRIENZER ROTHORN]  \n",
       "3              [06:08:00]  [LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...  \n",
       "4              [06:25:00]  [LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...  \n",
       "...                   ...                                                ...  \n",
       "86909          [20:59:00]        [GENEVE, BELLEGARDE (AIN), CULOZ, GRENOBLE]  \n",
       "86910          [08:24:00]         [GENEVE, BELLEGARDE (AIN), LYON PART DIEU]  \n",
       "86911          [09:25:00]         [GENEVE, BELLEGARDE (AIN), LYON PART DIEU]  \n",
       "86912          [14:33:00]         [GENEVE, BELLEGARDE (AIN), LYON PART DIEU]  \n",
       "86913          [21:34:00]         [GENEVE, BELLEGARDE (AIN), LYON PART DIEU]  \n",
       "\n",
       "[86914 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To add the sequence of stops to the route_hash_freq dataset '''\n",
    "route_hash_freq_Switzerland = pd.merge(route_hash_freq_Switzerland, trips_hash_stop_sequence_Switzerland[['route_id','hash', 'hash_inverse', 'service_id','stop_sequence']], on=['route_id', 'hash', 'hash_inverse', 'service_id'], how='left')\n",
    "route_hash_freq_Switzerland = route_hash_freq_Switzerland.drop_duplicates( subset = ['route_id', 'hash', 'service_id'], keep = 'first')\n",
    "route_hash_freq_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 2997146,
     "status": "ok",
     "timestamp": 1616025172067,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "VrHrgCSkkqNy",
    "outputId": "14c62975-2dec-4eed-f66a-49930be232ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>hash</th>\n",
       "      <th>hash_inverse</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>departure_time_first</th>\n",
       "      <th>departure_time_last</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>number_trip_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>936</td>\n",
       "      <td>[33248:1]</td>\n",
       "      <td>[05:50:00]</td>\n",
       "      <td>[05:58:00]</td>\n",
       "      <td>[LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.000044.028:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>869</td>\n",
       "      <td>[33249:1]</td>\n",
       "      <td>[06:08:00]</td>\n",
       "      <td>[06:16:00]</td>\n",
       "      <td>[LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001.000104.001:1</td>\n",
       "      <td>CC 1</td>\n",
       "      <td>3865371173043443348</td>\n",
       "      <td>-6836560398534858013</td>\n",
       "      <td>5072</td>\n",
       "      <td>[4117:1]</td>\n",
       "      <td>[07:36:00]</td>\n",
       "      <td>[08:36:00]</td>\n",
       "      <td>[BRIENZ BRB, PLANALP, BRIENZER ROTHORN]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002.000044.017:2</td>\n",
       "      <td>R 2</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>936</td>\n",
       "      <td>[33250:1]</td>\n",
       "      <td>[06:01:00]</td>\n",
       "      <td>[06:08:00]</td>\n",
       "      <td>[LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002.000044.024:2</td>\n",
       "      <td>R 2</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>869</td>\n",
       "      <td>[33251:1]</td>\n",
       "      <td>[06:18:00]</td>\n",
       "      <td>[06:25:00]</td>\n",
       "      <td>[LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86909</th>\n",
       "      <td>96806.000011.102:96806</td>\n",
       "      <td>TER 96806</td>\n",
       "      <td>1700149812652076650</td>\n",
       "      <td>256460250998497924</td>\n",
       "      <td>44307</td>\n",
       "      <td>[23292:1]</td>\n",
       "      <td>[18:39:00]</td>\n",
       "      <td>[20:59:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), CULOZ, GRENOBLE]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86910</th>\n",
       "      <td>96810.000011.101:96810</td>\n",
       "      <td>TER 96810</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>116609</td>\n",
       "      <td>[23293:1]</td>\n",
       "      <td>[06:16:00]</td>\n",
       "      <td>[08:24:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), LYON PART DIEU]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86911</th>\n",
       "      <td>96812.000011.101:96812</td>\n",
       "      <td>TER 96812</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>9453</td>\n",
       "      <td>[23294:1]</td>\n",
       "      <td>[07:17:00]</td>\n",
       "      <td>[09:25:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), LYON PART DIEU]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86912</th>\n",
       "      <td>96814.000011.101:96814</td>\n",
       "      <td>TER 96814</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>116609</td>\n",
       "      <td>[23295:1]</td>\n",
       "      <td>[12:25:00]</td>\n",
       "      <td>[14:33:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), LYON PART DIEU]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86913</th>\n",
       "      <td>96818.000011.101:96818</td>\n",
       "      <td>TER 96818</td>\n",
       "      <td>-4684204956159847117</td>\n",
       "      <td>-1289879366665992573</td>\n",
       "      <td>44307</td>\n",
       "      <td>[23296:1]</td>\n",
       "      <td>[19:26:00]</td>\n",
       "      <td>[21:34:00]</td>\n",
       "      <td>[GENEVE, BELLEGARDE (AIN), LYON PART DIEU]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86914 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     route_id route_long_name                 hash  \\\n",
       "0          00001.000044.018:1             R 1 -5189486139819647528   \n",
       "1          00001.000044.028:1             R 1 -5189486139819647528   \n",
       "2          00001.000104.001:1            CC 1  3865371173043443348   \n",
       "3          00002.000044.017:2             R 2  3242894917632905562   \n",
       "4          00002.000044.024:2             R 2  3242894917632905562   \n",
       "...                       ...             ...                  ...   \n",
       "86909  96806.000011.102:96806       TER 96806  1700149812652076650   \n",
       "86910  96810.000011.101:96810       TER 96810 -4684204956159847117   \n",
       "86911  96812.000011.101:96812       TER 96812 -4684204956159847117   \n",
       "86912  96814.000011.101:96814       TER 96814 -4684204956159847117   \n",
       "86913  96818.000011.101:96818       TER 96818 -4684204956159847117   \n",
       "\n",
       "              hash_inverse  service_id    trip_id departure_time_first  \\\n",
       "0      3242894917632905562         936  [33248:1]           [05:50:00]   \n",
       "1      3242894917632905562         869  [33249:1]           [06:08:00]   \n",
       "2     -6836560398534858013        5072   [4117:1]           [07:36:00]   \n",
       "3     -5189486139819647528         936  [33250:1]           [06:01:00]   \n",
       "4     -5189486139819647528         869  [33251:1]           [06:18:00]   \n",
       "...                    ...         ...        ...                  ...   \n",
       "86909   256460250998497924       44307  [23292:1]           [18:39:00]   \n",
       "86910 -1289879366665992573      116609  [23293:1]           [06:16:00]   \n",
       "86911 -1289879366665992573        9453  [23294:1]           [07:17:00]   \n",
       "86912 -1289879366665992573      116609  [23295:1]           [12:25:00]   \n",
       "86913 -1289879366665992573       44307  [23296:1]           [19:26:00]   \n",
       "\n",
       "      departure_time_last                                      stop_sequence  \\\n",
       "0              [05:58:00]  [LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...   \n",
       "1              [06:16:00]  [LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...   \n",
       "2              [08:36:00]            [BRIENZ BRB, PLANALP, BRIENZER ROTHORN]   \n",
       "3              [06:08:00]  [LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...   \n",
       "4              [06:25:00]  [LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...   \n",
       "...                   ...                                                ...   \n",
       "86909          [20:59:00]        [GENEVE, BELLEGARDE (AIN), CULOZ, GRENOBLE]   \n",
       "86910          [08:24:00]         [GENEVE, BELLEGARDE (AIN), LYON PART DIEU]   \n",
       "86911          [09:25:00]         [GENEVE, BELLEGARDE (AIN), LYON PART DIEU]   \n",
       "86912          [14:33:00]         [GENEVE, BELLEGARDE (AIN), LYON PART DIEU]   \n",
       "86913          [21:34:00]         [GENEVE, BELLEGARDE (AIN), LYON PART DIEU]   \n",
       "\n",
       "       number_trip_ids  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "86909                1  \n",
       "86910                1  \n",
       "86911                1  \n",
       "86912                1  \n",
       "86913                1  \n",
       "\n",
       "[86914 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To calculate the number of trip_ids in the list of trip_ids and to add it as a new attribute '''\n",
    "number_trip_ids_Switzerland = []\n",
    "for list_trip_ids_Switzerland in route_hash_freq_Switzerland['trip_id']:\n",
    "    count_Switzerland = len(list_trip_ids_Switzerland)\n",
    "    number_trip_ids_Switzerland.append(count_Switzerland)\n",
    "route_hash_freq_Switzerland['number_trip_ids'] = number_trip_ids_Switzerland\n",
    "\n",
    "route_hash_freq_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 998
    },
    "executionInfo": {
     "elapsed": 2997141,
     "status": "ok",
     "timestamp": 1616025172068,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "Khak0B6vkt2_",
    "outputId": "88e2f4ee-7c3d-425f-b563-ba02f16661d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>hash</th>\n",
       "      <th>hash_inverse</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>departure_time_first</th>\n",
       "      <th>departure_time_last</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>number_trip_ids</th>\n",
       "      <th>dates</th>\n",
       "      <th>count_service_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.000044.018:1</td>\n",
       "      <td>R 1</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>936</td>\n",
       "      <td>[33248:1]</td>\n",
       "      <td>[05:50:00]</td>\n",
       "      <td>[05:58:00]</td>\n",
       "      <td>[LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.000044.017:2</td>\n",
       "      <td>R 2</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>936</td>\n",
       "      <td>[33250:1]</td>\n",
       "      <td>[06:01:00]</td>\n",
       "      <td>[06:08:00]</td>\n",
       "      <td>[LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00005.000044.018:5</td>\n",
       "      <td>R 5</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>936</td>\n",
       "      <td>[33256:1]</td>\n",
       "      <td>[06:50:00]</td>\n",
       "      <td>[06:58:00]</td>\n",
       "      <td>[LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00006.000044.018:6</td>\n",
       "      <td>R 6</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>936</td>\n",
       "      <td>[33258:1]</td>\n",
       "      <td>[07:01:00]</td>\n",
       "      <td>[07:08:00]</td>\n",
       "      <td>[LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007.000044.017:7</td>\n",
       "      <td>R 7</td>\n",
       "      <td>-5189486139819647528</td>\n",
       "      <td>3242894917632905562</td>\n",
       "      <td>936</td>\n",
       "      <td>[33260:1]</td>\n",
       "      <td>[07:17:00]</td>\n",
       "      <td>[07:25:00]</td>\n",
       "      <td>[LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57323</th>\n",
       "      <td>96760.000011.101:L6</td>\n",
       "      <td>L6</td>\n",
       "      <td>-8393100017709903846</td>\n",
       "      <td>-7876505502063812119</td>\n",
       "      <td>28493</td>\n",
       "      <td>[23263:1]</td>\n",
       "      <td>[20:18:00]</td>\n",
       "      <td>[20:41:00]</td>\n",
       "      <td>[GENEVE, VERNIER, MEYRIN, ZIMEYSA, SATIGNY, RU...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57324</th>\n",
       "      <td>96761.000011.101:L6</td>\n",
       "      <td>L6</td>\n",
       "      <td>-5956246458137668248</td>\n",
       "      <td>3602218816774858122</td>\n",
       "      <td>28493</td>\n",
       "      <td>[23264:1]</td>\n",
       "      <td>[19:36:00]</td>\n",
       "      <td>[19:57:00]</td>\n",
       "      <td>[POUGNY-CHANCY, RUSSIN, SATIGNY, ZIMEYSA, MEYR...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57325</th>\n",
       "      <td>96763.000011.101:L6</td>\n",
       "      <td>L6</td>\n",
       "      <td>-5956246458137668248</td>\n",
       "      <td>3602218816774858122</td>\n",
       "      <td>24237</td>\n",
       "      <td>[23265:1]</td>\n",
       "      <td>[20:36:00]</td>\n",
       "      <td>[21:00:00]</td>\n",
       "      <td>[POUGNY-CHANCY, RUSSIN, SATIGNY, ZIMEYSA, MEYR...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210701, 20210702, 20210705, 20210706, 20210...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57326</th>\n",
       "      <td>96765.000011.101:L6</td>\n",
       "      <td>L6</td>\n",
       "      <td>-5956246458137668248</td>\n",
       "      <td>3602218816774858122</td>\n",
       "      <td>117674</td>\n",
       "      <td>[23267:1]</td>\n",
       "      <td>[21:36:00]</td>\n",
       "      <td>[22:00:00]</td>\n",
       "      <td>[POUGNY-CHANCY, RUSSIN, SATIGNY, ZIMEYSA, MEYR...</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210315, 20210316, 20210317, 20210318, 20210...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57327</th>\n",
       "      <td>96785.87_LEX.001:L6</td>\n",
       "      <td>L6</td>\n",
       "      <td>-5144642795514258850</td>\n",
       "      <td>-7142285692308890961</td>\n",
       "      <td>65904</td>\n",
       "      <td>[47667:1]</td>\n",
       "      <td>[19:37:00]</td>\n",
       "      <td>[19:47:00]</td>\n",
       "      <td>[BELLEGARDE (AIN), POUGNY-CHANCY]</td>\n",
       "      <td>1</td>\n",
       "      <td>{20210412, 20210413, 20210414, 20210415, 20210...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57328 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  route_id route_long_name                 hash  \\\n",
       "0       00001.000044.018:1             R 1 -5189486139819647528   \n",
       "1       00002.000044.017:2             R 2  3242894917632905562   \n",
       "2       00005.000044.018:5             R 5 -5189486139819647528   \n",
       "3       00006.000044.018:6             R 6  3242894917632905562   \n",
       "4       00007.000044.017:7             R 7 -5189486139819647528   \n",
       "...                    ...             ...                  ...   \n",
       "57323  96760.000011.101:L6              L6 -8393100017709903846   \n",
       "57324  96761.000011.101:L6              L6 -5956246458137668248   \n",
       "57325  96763.000011.101:L6              L6 -5956246458137668248   \n",
       "57326  96765.000011.101:L6              L6 -5956246458137668248   \n",
       "57327  96785.87_LEX.001:L6              L6 -5144642795514258850   \n",
       "\n",
       "              hash_inverse  service_id    trip_id departure_time_first  \\\n",
       "0      3242894917632905562         936  [33248:1]           [05:50:00]   \n",
       "1     -5189486139819647528         936  [33250:1]           [06:01:00]   \n",
       "2      3242894917632905562         936  [33256:1]           [06:50:00]   \n",
       "3     -5189486139819647528         936  [33258:1]           [07:01:00]   \n",
       "4      3242894917632905562         936  [33260:1]           [07:17:00]   \n",
       "...                    ...         ...        ...                  ...   \n",
       "57323 -7876505502063812119       28493  [23263:1]           [20:18:00]   \n",
       "57324  3602218816774858122       28493  [23264:1]           [19:36:00]   \n",
       "57325  3602218816774858122       24237  [23265:1]           [20:36:00]   \n",
       "57326  3602218816774858122      117674  [23267:1]           [21:36:00]   \n",
       "57327 -7142285692308890961       65904  [47667:1]           [19:37:00]   \n",
       "\n",
       "      departure_time_last                                      stop_sequence  \\\n",
       "0              [05:58:00]  [LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...   \n",
       "1              [06:08:00]  [LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...   \n",
       "2              [06:58:00]  [LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...   \n",
       "3              [07:08:00]  [LE LOCLE, LE LOCLE LE CHALET, LES FRETES, LES...   \n",
       "4              [07:25:00]  [LES BRENETS, LES FRETES, LE LOCLE LE CHALET, ...   \n",
       "...                   ...                                                ...   \n",
       "57323          [20:41:00]  [GENEVE, VERNIER, MEYRIN, ZIMEYSA, SATIGNY, RU...   \n",
       "57324          [19:57:00]  [POUGNY-CHANCY, RUSSIN, SATIGNY, ZIMEYSA, MEYR...   \n",
       "57325          [21:00:00]  [POUGNY-CHANCY, RUSSIN, SATIGNY, ZIMEYSA, MEYR...   \n",
       "57326          [22:00:00]  [POUGNY-CHANCY, RUSSIN, SATIGNY, ZIMEYSA, MEYR...   \n",
       "57327          [19:47:00]                  [BELLEGARDE (AIN), POUGNY-CHANCY]   \n",
       "\n",
       "       number_trip_ids                                              dates  \\\n",
       "0                    1  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "1                    1  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "2                    1  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "3                    1  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "4                    1  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "...                ...                                                ...   \n",
       "57323                1  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "57324                1  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "57325                1  {20210701, 20210702, 20210705, 20210706, 20210...   \n",
       "57326                1  {20210315, 20210316, 20210317, 20210318, 20210...   \n",
       "57327                1  {20210412, 20210413, 20210414, 20210415, 20210...   \n",
       "\n",
       "       count_service_id  \n",
       "0                    83  \n",
       "1                    83  \n",
       "2                    83  \n",
       "3                    83  \n",
       "4                    83  \n",
       "...                 ...  \n",
       "57323                78  \n",
       "57324                78  \n",
       "57325                78  \n",
       "57326                68  \n",
       "57327                 7  \n",
       "\n",
       "[57328 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' To merge the route_hash_freq_Switzerland df with the service_id_dates to get the sets of corresponding dates '''\n",
    "route_hash_service_freq_Switzerland = pd.merge(route_hash_freq_Switzerland, service_id_dates_Switzerland, on='service_id', how='inner')\n",
    "route_hash_service_freq_Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlWKRRzylPxk"
   },
   "source": [
    "## Functions for the route creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811927,
     "status": "ok",
     "timestamp": 1616025986873,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "9ZovJ8kXlTCq"
   },
   "outputs": [],
   "source": [
    "'''Some functions to better factorise the functions in the coming cells'''\n",
    "\n",
    "def select_stop_sequences(stop_sequences_df, route_id):\n",
    "    '''retruns the stop sequences with the selected route_id'''\n",
    "    return stop_sequences_df[stop_sequences_df['route_id'] == route_id].copy()\n",
    "\n",
    "\n",
    "def take_leftovers_list_c_from_intersection_AAndB(list_a, list_b, list_c):\n",
    "    '''take the indexes of the intersection of list a with list b and retain the elments of list c with that index'''\n",
    "    ind_dict = dict((k,i) for i,k in enumerate(list_a))\n",
    "    return [list_c[ind_dict[x]] for x in (set(list_a).intersection(list_b))]\n",
    "\n",
    "def get_extentions (after_or_behind, route_sequences_route_id, trip):\n",
    "    '''returns the extentions for the trip (behind or after)'''\n",
    "    if after_or_behind == 'after':\n",
    "        #checks the extentions possible for the trip that can follow after its last stop\n",
    "        possible_extentions = route_sequences_route_id[route_sequences_route_id['stop_sequence'].apply(lambda x: any(item for item in [trip['stop_sequence'][-1]] if (item == x[0]) and not(set(x[1:]) & set(trip['stop_sequence']))))].copy()\n",
    "    elif after_or_behind == 'behind':\n",
    "        #checks the extentions possible for the trip that can follow before its first stop\n",
    "        possible_extentions = route_sequences_route_id[route_sequences_route_id['stop_sequence'].apply(lambda x: any(item for item in [trip['stop_sequence'][0]] if (item == x[-1]) and not(set(x[:-1]) & set(trip['stop_sequence']))))].copy()        \n",
    "    #checks that those extentions have a common date as the trip\n",
    "    possible_extentions = possible_extentions[possible_extentions['dates'].apply(lambda x: any(item for item in trip['dates'] if item in x))].copy()   \n",
    "    if not possible_extentions.empty: \n",
    "        if after_or_behind == 'after':\n",
    "            #checks that those extentions have a matching time schedule as the trip\n",
    "            possible_extentions = possible_extentions[possible_extentions['departure_time_first'].apply(lambda x: any(item for item in trip['departure_time_last'] if item in x))].copy()\n",
    "        elif after_or_behind == 'behind':\n",
    "            #checks that those extentions have a matching time schedule as the trip\n",
    "            possible_extentions = possible_extentions[possible_extentions['departure_time_last'].apply(lambda x: any(item for item in trip['departure_time_first'] if item in x))].copy()\n",
    "    return possible_extentions      \n",
    "\n",
    "def calculate_frequency (sequences_df):\n",
    "    '''calculate the frequency based on the length of the dates and departure_time and put the hash in as a column of list'''\n",
    "    sequences_df['number_dates'] = sequences_df['dates'].apply(lambda x: len(x))\n",
    "    sequences_df['number_times'] = sequences_df['departure_time_last'].apply(lambda x: len(x))\n",
    "    sequences_df['frequency'] = sequences_df['number_dates']* sequences_df['number_times'] \n",
    "    sequences_df = sequences_df.drop(['dates', 'departure_time_last', 'number_dates', 'number_times'], axis=1)\n",
    "    sequences_df['hash'] = sequences_df['hash'].apply(lambda x: [x])\n",
    "    return sequences_df.copy()\n",
    "         \n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "FMT = '%H:%M:%S'\n",
    "day_in_seconds = timedelta(days=1).total_seconds()\n",
    "def calculate_time_difference(time_df, later_time, earlier_time, column_name):\n",
    "    '''calculates the time difference between later time and earlier time and put it in time_df[column_name]'''\n",
    "    #transform 24:00:00 into 00:00:00\n",
    "    time_df['departure_time'] = time_df['departure_time'].apply(lambda x: str(int(x[:2])-24) + x[2:] if int(x[:2]) >= 24 else x)\n",
    "    time_df['arrival_time'] = time_df['arrival_time'].apply(lambda x: str(int(x[:2])-24) + x[2:] if int(x[:2]) >=  24 else x)\n",
    "    #calculate the waiting_time\n",
    "    time_df[column_name] = time_df[['arrival_time','departure_time']].apply(lambda x: int((datetime.strptime(x[later_time], FMT) - datetime.strptime(x[earlier_time], FMT)).total_seconds()/60), axis=1)\n",
    "    #if one day as past, take it into consideration\n",
    "    time_df[column_name] = time_df[column_name].apply(lambda x: day_in_seconds/60 + x if x < 0 else x)\n",
    "    return time_df            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811925,
     "status": "ok",
     "timestamp": 1616025986877,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "bQhpgRFAlaWb"
   },
   "outputs": [],
   "source": [
    "'''Finds the routes that can be either extended from behind or from after and those which are complete sequences'''\n",
    "\n",
    "def get_extention_indexes(stop_sequences_df):\n",
    "    '''returns the tree indexes: index_of_extendable, index_of_begin_sequences, index_of_complete_sequences'''\n",
    "    #intiate the dictionnaries, that will be used to retrieve different rows later on\n",
    "    index_of_extendable = {}\n",
    "    index_of_begin_sequences = {}\n",
    "    index_of_complete_sequences = {}\n",
    "    for route_id in stop_sequences_df['route_id'].unique():\n",
    "        #select the route with the route_id selected by the loop iteration\n",
    "        route_sequences_route_id = select_stop_sequences(stop_sequences_df, route_id)\n",
    "        for index_trip, trip in route_sequences_route_id.iterrows():\n",
    "            #checks the extentions possible for the trip that can follow after its last stop\n",
    "            possible_extentions_after = get_extentions('after', route_sequences_route_id, trip)\n",
    "            #checks the extentions possible for the trip that can follow before its first stop\n",
    "            possible_extentions_behind = get_extentions('behind', route_sequences_route_id, trip)\n",
    "            #put all the sequences that can be extended either from the beginning either from the end together\n",
    "            possible_extentions = possible_extentions_after.append(possible_extentions_behind, ignore_index = True)\n",
    "            if not possible_extentions.empty:\n",
    "                if route_id not in index_of_extendable:\n",
    "                    index_of_extendable[route_id] = []\n",
    "                index_of_extendable[route_id].append(index_trip)\n",
    "                if possible_extentions_behind.empty:\n",
    "                    if route_id not in index_of_begin_sequences:\n",
    "                        index_of_begin_sequences[route_id] = []\n",
    "                    index_of_begin_sequences[route_id].append(index_trip)\n",
    "            elif possible_extentions.empty:\n",
    "                if route_id not in index_of_complete_sequences:\n",
    "                    index_of_complete_sequences[route_id] = []\n",
    "                index_of_complete_sequences[route_id].append(index_trip)\n",
    "                \n",
    "    return index_of_extendable, index_of_begin_sequences, index_of_complete_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811920,
     "status": "ok",
     "timestamp": 1616025986878,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "TwPRXlQ4lcT2"
   },
   "outputs": [],
   "source": [
    "'''Creates all the sequences of routes possible to reconstruct the real route'''\n",
    "\n",
    "def possible_sequences_construction(stop_sequences_df, index_of_extendable, index_of_begin_sequences, index_of_complete_sequences):\n",
    "    '''returns the first part of the route_creation, two others need to be added'''\n",
    "    import copy\n",
    "    #create an empty df for the process of route creation\n",
    "    route_creation  = pd.DataFrame()\n",
    "    for route_id in index_of_extendable:\n",
    "        #checks if some parts are begin sequences, if not, then we can't build routes with multiple sequences\n",
    "        if route_id in index_of_begin_sequences:\n",
    "            #create a copy of the df with only the route considered in the loop iteration\n",
    "            routes_with_route_id = select_stop_sequences(stop_sequences_df, route_id)\n",
    "            #set default frequency to NaN\n",
    "            routes_with_route_id['frequency'] = np.nan\n",
    "            #create a df where only the routes that have an end stop as their first element of the sequence\n",
    "            route_creation_route_id = routes_with_route_id.loc[index_of_begin_sequences[route_id]][['route_id', 'hash', 'stop_sequence', 'dates', 'departure_time_last','frequency']]\n",
    "            #create a df with the exentable sequences for that route_id\n",
    "            route_creation_extensions_route_id = routes_with_route_id.loc[index_of_extendable[route_id]][['route_id', 'hash', 'stop_sequence', 'dates', 'departure_time_first', 'departure_time_last','frequency']]    \n",
    "            #make the hash column as a column of lists\n",
    "            route_creation_route_id['hash'] = route_creation_route_id['hash'].apply(lambda x: [x])\n",
    "            route_creation_route_id = route_creation_route_id.reset_index(drop=True)\n",
    "            #to stop the while loop when all the routes are complete in the df for the route_id of the loop iteration\n",
    "            complete_routes = 0\n",
    "            while complete_routes < len(route_creation_route_id.index):\n",
    "                #use a deepcopy to not impact the iterrows of the main loop\n",
    "                route_creation_deep_copy = copy.deepcopy(route_creation_route_id)\n",
    "                for index_original, route_part in route_creation_deep_copy.iterrows():\n",
    "                    #create a dataframe of the possible extentions for each route_part\n",
    "                    #select an extention only if the extention is the next part of the route and also that no other station are repeated in the sequence if this extention is added(otherwise it might cause an infinite loop)\n",
    "                    possible_extentions = get_extentions('after', route_creation_extensions_route_id, route_part)\n",
    "                    #checks whether any extention fullfilling the criterias has been found\n",
    "                    if not possible_extentions.empty:\n",
    "                        #if so, extend it with every single possibilities\n",
    "                        for index_extention, possible_extention in possible_extentions.iterrows():\n",
    "                            #must create a deepcopy, otherwise the orignal hash list will change as well (mutable)\n",
    "                            updated_hash = copy.deepcopy(route_part['hash'])\n",
    "                            updated_hash.append(possible_extention['hash'])\n",
    "                            updated_route_sequence = route_part['stop_sequence'] + possible_extention['stop_sequence'][1:]\n",
    "                            common_dates = possible_extention['dates'] & route_part['dates']\n",
    "                            new_departure_time_last = take_leftovers_list_c_from_intersection_AAndB(list(possible_extentions['departure_time_first'])[0], list(route_part['departure_time_last']), list(possible_extentions['departure_time_last'])[0])\n",
    "                            new_frequency = len(new_departure_time_last) * len(common_dates)\n",
    "                            route_creation_route_id.loc[max(route_creation_route_id.index)+1] = [route_id, updated_hash, updated_route_sequence, common_dates, new_departure_time_last, new_frequency]\n",
    "                        #then delete the route with the index (see loop here above)\n",
    "                        route_creation_route_id = route_creation_route_id.drop(index = index_original)            \n",
    "                    #the route can't be extended anymore\n",
    "                    else:\n",
    "                        complete_routes += 1\n",
    "            #adds all the possible routes created with the trips of the route_id of the main loop\n",
    "            route_creation = route_creation.append(route_creation_route_id, ignore_index = True)\n",
    "    if 'departure_time_last' in route_creation.columns:\n",
    "        route_creation = route_creation.drop(['dates', 'departure_time_last'], axis=1)\n",
    "    route_creation = route_creation.reindex(columns=['route_id','hash','stop_sequence', 'frequency'])\n",
    "    return route_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811915,
     "status": "ok",
     "timestamp": 1616025986879,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "DfWI7W2hleCY"
   },
   "outputs": [],
   "source": [
    "'''Adds the full sequences to the route_creation dataframe'''\n",
    "\n",
    "def add_full_sequences(stop_sequences_df, route_creation, index_of_complete_sequences):\n",
    "    '''returns the second part of the route_creation, one other needs to be added'''\n",
    "    for route_id in index_of_complete_sequences:\n",
    "        #findes all the complete sequences for that route_id\n",
    "        copy_complete_sequences_df = stop_sequences_df.loc[index_of_complete_sequences[route_id]][['route_id','hash','stop_sequence', 'dates', 'departure_time_last']].copy()\n",
    "        copy_complete_sequences_df = calculate_frequency(copy_complete_sequences_df)\n",
    "        #adds each of them in the route_creation dataframe\n",
    "        for index_complete_sequence, complete_sequence in copy_complete_sequences_df.iterrows():\n",
    "            route_creation = route_creation.append(complete_sequence, ignore_index = True)\n",
    "    route_creation = route_creation.sort_values(by=['route_id'], ignore_index = True)\n",
    "    return route_creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811910,
     "status": "ok",
     "timestamp": 1616025986880,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "OfgbvGPqliaB"
   },
   "outputs": [],
   "source": [
    "'''Adds the sequences that were not yet added in the route_creation dataframe'''\n",
    "\n",
    "def add_unused_sequences(stop_sequences_df, route_creation):\n",
    "    '''returns the third part of the route_creation'''\n",
    "    for route_id in stop_sequences_df['route_id'].unique():\n",
    "        if route_id in route_creation['route_id'].unique():\n",
    "            #get a set of the hashes that were employed to create the routes for that route_id\n",
    "            used_sequences_hash = set(route_creation[route_creation['route_id'] == route_id].apply(lambda x: pd.Series(x['hash']),axis=1).stack().reset_index(level=1, drop=True))\n",
    "            #get a tuple of all the route sequences for that route_id\n",
    "            used_sequences = tuple(route_creation[route_creation['route_id'] == route_id]['stop_sequence'])\n",
    "            copy_sequences_route_id = select_stop_sequences(stop_sequences_df, route_id)[['route_id','hash','stop_sequence', 'dates', 'departure_time_last']]\n",
    "            copy_sequences_route_id = calculate_frequency(copy_sequences_route_id)\n",
    "            #adds the hashes that were not employed in any route creations for that route_id\n",
    "            for index_trip, trip in copy_sequences_route_id.iterrows():\n",
    "                #first element of the list because there is always only one element\n",
    "                if trip['hash'][0] not in used_sequences_hash:\n",
    "                    #checks that the sequence is not a sublist of any existing sequences\n",
    "                    is_subsequence = False\n",
    "                    for sequence in used_sequences:\n",
    "                        if set(trip['stop_sequence']).issubset(sequence):\n",
    "                            is_subsequence = True\n",
    "                    if not is_subsequence:\n",
    "                        route_creation = route_creation.append(trip, ignore_index = True)\n",
    "    return route_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creates a column in the df that calculates the travel time between the first and last stop (waiting time included)'''\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "FMT = '%H:%M:%S'\n",
    "day_in_seconds = timedelta(days=1).total_seconds()\n",
    "\n",
    "def give_begin_end_time(route_creation_frequency_single, trips_hash_stop_sequence, stops_cleaned_stop_times_trips_merge_dates):\n",
    "    #create a copy to not change the input DataFrame\n",
    "    route_creation_frequency_single = route_creation_frequency_single.copy()\n",
    "    #makes a column with the a representative begin time and end time of the route\n",
    "    route_creation_frequency_single['travel_time'] = np.nan\n",
    "    for index_sequence, sequence in route_creation_frequency_single.iterrows():\n",
    "        constructed_route = pd.DataFrame()\n",
    "        for index_hash, hash_value in enumerate(sequence['hash']):\n",
    "            index_plus_one = index_hash + 1\n",
    "            #take all the trips with that hash\n",
    "            next_representative_trips = trips_hash_stop_sequence[(trips_hash_stop_sequence['hash'] == hash_value) & (trips_hash_stop_sequence['route_id'] == sequence['route_id'])].copy()['trip_id']\n",
    "            #take all the stop sequences and their time that belongs \n",
    "            full_times = stops_cleaned_stop_times_trips_merge_dates[stops_cleaned_stop_times_trips_merge_dates['trip_id'].isin(next_representative_trips)].copy()\n",
    "            #select) only the last stop sequences of full_times for each trip_id\n",
    "            new_index_max_per_trip_id = full_times.reset_index().groupby(['route_id', 'trip_id'])['stop_sequence'].idxmax()\n",
    "            max_per_trip_id = full_times.reset_index().loc[new_index_max_per_trip_id]\n",
    "            #select only the first stop sequences of full_times for each trip_id            \n",
    "            new_index_min_per_trip_id = full_times.reset_index().groupby(['route_id', 'trip_id'])['stop_sequence'].idxmin()            \n",
    "            min_per_trip_id = full_times.reset_index().loc[new_index_min_per_trip_id]\n",
    "            #merge max_per_trip_id and min_per_trip_id\n",
    "            merged = min_per_trip_id[['trip_id', 'dates', 'departure_time']].merge(max_per_trip_id[['trip_id', 'arrival_time', 'departure_time']], on='trip_id')\n",
    "            #take all the stop sequences except the first one, and the last one if it is not the last sequence of the route\n",
    "            if index_hash == len(sequence['hash']) - 1:\n",
    "                rest_per_trip_id = full_times.reset_index().drop(pd.concat([new_index_min_per_trip_id,new_index_max_per_trip_id]))\n",
    "            else:\n",
    "                rest_per_trip_id = full_times.reset_index().drop(new_index_min_per_trip_id)            \n",
    "            rest_per_trip_id = rest_per_trip_id.dropna()\n",
    "            if not rest_per_trip_id.empty:\n",
    "                rest_per_trip_id = calculate_time_difference(rest_per_trip_id, 'departure_time', 'arrival_time', 'waiting_time')\n",
    "                #calculate the total waiting_time\n",
    "                rest_per_trip_id_grouped = rest_per_trip_id.groupby(['trip_id'], as_index=False)['waiting_time'].sum()\n",
    "                merged_waiting_time = merged.merge(rest_per_trip_id_grouped, on='trip_id')\n",
    "            #in case there are only two stops in for the hash\n",
    "            else:\n",
    "                merged_waiting_time = merged.copy()\n",
    "                merged_waiting_time['waiting_time'] = 0\n",
    "            #rename the columns     \n",
    "            merged_waiting_time = merged_waiting_time.rename(columns = {'trip_id': 'trip_id_' + str(index_plus_one),'departure_time_x':'departure_time_'+ str(index_plus_one), 'arrival_time':'arrival_time_'+ str(index_plus_one),\n",
    "                                          'departure_time_y':'departure_time_'+ str(index_plus_one + 1), 'waiting_time': 'waiting_time_' + str(index_plus_one)})\n",
    "            if index_hash == 0:\n",
    "                constructed_route = merged_waiting_time\n",
    "            elif index_hash > 0:\n",
    "                constructed_route = constructed_route.merge(merged_waiting_time, how='inner', on=['departure_time_' + str(index_plus_one)])\n",
    "                #take the intersection of the dates => only get the common dates and retain those rows with common dates\n",
    "                constructed_route['dates'] = [a & b for a,b in zip(constructed_route['dates_x'], constructed_route['dates_y'])]\n",
    "                constructed_route = constructed_route[constructed_route['dates'].map(lambda d: len(d)) > 0]\n",
    "                constructed_route = constructed_route.drop(['dates_x','dates_y'], axis=1)        \n",
    "        #make a list of all the columns of waiting_times\n",
    "        list_column_waiting_time = []\n",
    "        for i in range(1, index_plus_one + 1):\n",
    "            list_column_waiting_time.append('waiting_time_' + str(i))\n",
    "        #sum all the waiting times together for each route itinerary\n",
    "        constructed_route['waiting_time'] = constructed_route[list_column_waiting_time].astype(int).sum(1)\n",
    "        \n",
    "        #sometimes it is impossible to find trips that follow each other\n",
    "        if not constructed_route.empty:\n",
    "            #when the loop is finished, take the last arrival time, that will be used to calculate the travel time\n",
    "            time_constructed_route = constructed_route[['departure_time_1', 'arrival_time_' + str(index_plus_one), 'waiting_time', 'dates']]\n",
    "            time_constructed_route = time_constructed_route.rename(columns = {'departure_time_1':'departure_time', 'arrival_time_' + str(index_plus_one):'arrival_time'})\n",
    "            time_constructed_route = calculate_time_difference(time_constructed_route, 'arrival_time', 'departure_time', 'time_diff_min')\n",
    "            #add here a new column count dates that is the sum of the common dates\n",
    "            time_constructed_route['count_dates'] = time_constructed_route['dates'].apply(lambda x: len(x))\n",
    "            sum_count_dates = time_constructed_route['count_dates'].sum()\n",
    "            #take the first most frequent one\n",
    "            #create the weighted sum\n",
    "            time_constructed_route['WS_travel_time'] = (time_constructed_route['time_diff_min'] * time_constructed_route['count_dates'])/sum_count_dates\n",
    "            time_constructed_route['WS_waiting_time'] = (time_constructed_route['waiting_time'] * time_constructed_route['count_dates'])/sum_count_dates    \n",
    "            weighted_sum_tt = time_constructed_route['WS_travel_time'].sum()\n",
    "            weighted_sum_wt = time_constructed_route['WS_waiting_time'].sum()\n",
    "            #Add this to the first dataframe\n",
    "            route_creation_frequency_single.loc[index_sequence,'travel_time'] = weighted_sum_tt\n",
    "            route_creation_frequency_single.loc[index_sequence,'waiting_time'] = weighted_sum_wt\n",
    "        #if there is no trips that follow each other with the hash from the array\n",
    "        else:\n",
    "            route_creation_frequency_single = route_creation_frequency_single.drop(index_sequence)\n",
    "            \n",
    "    return route_creation_frequency_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811906,
     "status": "ok",
     "timestamp": 1616025986887,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "nkZPE39slnEx"
   },
   "outputs": [],
   "source": [
    "def calculate_hash_route_creation(route_creation): \n",
    "    '''calculates the hash and the hash inverse of the route_creation'''\n",
    "    #copy the route_creation dataFrame\n",
    "    route_creation_hash = route_creation.copy()\n",
    "    #calculate the hash and the hash inverse using the lists in stop_sequence\n",
    "    route_creation_hash['hash'] = route_creation_hash['stop_sequence'].apply(lambda x: hash(tuple(x)))\n",
    "    route_creation_hash['hash_inverse'] = route_creation_hash['stop_sequence'].apply(lambda x: hash(tuple(x[::-1])))\n",
    "    return route_creation_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811901,
     "status": "ok",
     "timestamp": 1616025986888,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "4hbIXoVvlopO"
   },
   "outputs": [],
   "source": [
    "'''Regroup the routes that are the same (even though they are in the opposite direction)'''\n",
    "\n",
    "def regroup_same_stop_sequences(route_creation_hash):\n",
    "    '''regroups the stop_sequences that are the same'''\n",
    "    \n",
    "    route_creation_max_hash = route_creation_hash.copy()\n",
    "    route_creation_max_hash['max_hash'] = route_creation_max_hash[['hash', 'hash_inverse']].max(axis=1)\n",
    "    #create a df that sums the frequence of the trips going from opposite directions\n",
    "    route_creation_max_hash_freq = route_creation_max_hash.groupby(['route_id','max_hash'], as_index = False)[['frequency']].sum()\n",
    "    #renames the max_hash column into hash so it the dataframe can be merged with route_hash_without_freq\n",
    "    route_creation_max_hash_freq = route_creation_max_hash_freq.rename(columns = {'max_hash':'hash'})\n",
    "    #drops the column freq_sequence_route because the one that is of interest is in route_creation_max_hash_freq\n",
    "    route_hash_without_freq = route_creation_hash.copy().drop(['frequency'], axis = 1)\n",
    "    route_hash_without_freq = route_hash_without_freq.drop_duplicates(subset=['route_id', 'hash'])\n",
    "    route_hash_freq_combined_first_merge = pd.merge(route_creation_max_hash_freq, route_hash_without_freq, on=['route_id', 'hash'], how='left')\n",
    "    #selects the part of the dataset that doesn't have NaN (because for the NaN, their hash_value that was max was the one in hash_inverse and it didn't exist in the other df), so we can concatenate it with the part that had NaN later\n",
    "    route_hash_freq_first_part = route_hash_freq_combined_first_merge[pd.notnull(route_hash_freq_combined_first_merge['stop_sequence'])]\n",
    "    #selects one part the part of the dataset that does have NaN, so we can concatenate it with the part that has no NaN later on.\n",
    "    #but first, we will need to fill those NaN values (done in the code lines behind this one)\n",
    "    route_hash_freq_second_part = route_hash_freq_combined_first_merge[pd.isnull(route_hash_freq_combined_first_merge['stop_sequence'])][['route_id', 'hash', 'frequency']]\n",
    "    #renames the hash column into hash_inverse so it the dataframe can be merged with route_hash_without_freq (because it didn't work with 'hash' on the first merge)\n",
    "    route_hash_freq_second_part = route_hash_freq_second_part.rename(columns = {'hash':'hash_inverse'})\n",
    "    route_hash_freq_second_part = pd.merge(route_hash_freq_second_part, route_hash_without_freq, on=['route_id', 'hash_inverse'], how='left')\n",
    "    #the hash that is of interest in the final df will be hash and not hash_inverse\n",
    "    route_hash_freq_combined_not_sorted = pd.concat([route_hash_freq_first_part, route_hash_freq_second_part])\n",
    "    route_hash_freq_combined = route_hash_freq_combined_not_sorted.sort_values(by = ['route_id'])\n",
    "    route_hash_freq_combined = route_hash_freq_combined.reset_index(drop = True)\n",
    "    return route_hash_freq_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811897,
     "status": "ok",
     "timestamp": 1616025986891,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "tZWIOR7BlqOD"
   },
   "outputs": [],
   "source": [
    "'''Deletes the routes that do not represent 10% of the total route frequency and creates new route, if some of them are different'''\n",
    "\n",
    "def apply_treshold_route_creation(route_hash_freq_combined): \n",
    "    #calculates the total frequency per route_id\n",
    "    frequency_each_route = route_hash_freq_combined.groupby(['route_id'], as_index = False)['frequency'].sum()\n",
    "    frequency_treshold = frequency_each_route.copy()\n",
    "    #calculates the treshold (here 10%)\n",
    "    frequency_treshold['frequency'] = frequency_treshold['frequency']/10\n",
    "    frequency_treshold.rename(columns = {'frequency':'frequency_treshold'}, inplace = True)\n",
    "    route_hash_freq_treshold = route_hash_freq_combined.merge(frequency_treshold, on='route_id', how = 'left')\n",
    "    #find the sequences that are not more than 10% of the route frequency and delete them\n",
    "    index_names = route_hash_freq_treshold[route_hash_freq_treshold['frequency'] < route_hash_freq_treshold['frequency_treshold']].index\n",
    "    route_hash_freq_treshold.drop(index_names, inplace = True)\n",
    "    #drop the routes with the same hash as others\n",
    "    route_hash_freq_treshold['max_hash'] = route_hash_freq_treshold[['hash', 'hash_inverse']].max(axis=1)\n",
    "    route_hash_freq_treshold = route_hash_freq_treshold.drop_duplicates(subset='max_hash')\n",
    "    route_hash_freq_treshold  = route_hash_freq_treshold.drop(['hash_inverse', 'max_hash'], axis = 1)\n",
    "    #selects the sequences that are not the first most frequent per route_id\n",
    "    sequences_max_freq = route_hash_freq_treshold.groupby(['route_id'],as_index = False)['frequency'].max()\n",
    "    sequences_max_freq.rename(columns = {'frequency':'max_frequency'}, inplace = True)\n",
    "    sequences_max_freq_merged = route_hash_freq_treshold.merge(sequences_max_freq, on='route_id', how='left')\n",
    "    sequences_max_freq_index = sequences_max_freq_merged[sequences_max_freq_merged['frequency'] == sequences_max_freq_merged['max_frequency']].drop_duplicates(subset='route_id').index\n",
    "    sequences_non_max_freq_index = sequences_max_freq_merged[~sequences_max_freq_merged.index.isin(sequences_max_freq_index)].index\n",
    "    #those selected sequences get a new route_id that starts from routes['route_id'].max() + 1 and increments by one for each new route\n",
    "    route_id_creation =  0 + 1\n",
    "    new_route_id_column = list(range(route_id_creation, route_id_creation + len(sequences_non_max_freq_index)))    \n",
    "    sequences_max_freq_merged.loc[sequences_non_max_freq_index, 'route_id'] = new_route_id_column\n",
    "    #keep only the column route_id and stop_sequence\n",
    "    final_routes = sequences_max_freq_merged.drop(sequences_max_freq_merged[sequences_max_freq_merged['frequency'] == 0].index)\n",
    "    final_routes = final_routes.drop(columns=['hash', 'frequency', 'frequency_treshold', 'max_frequency'])\n",
    "    return final_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811895,
     "status": "ok",
     "timestamp": 1616025986892,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "g3Q139pNamQu"
   },
   "outputs": [],
   "source": [
    "''' To keep only the routes that have at least one Swiss station in their route_sequence'''\n",
    "\n",
    "def keep_swiss_routes(final_routes):\n",
    "    non_swiss_routes = set()\n",
    "    for index_route, route in final_routes.iterrows():\n",
    "        is_in_Switzerland = False\n",
    "        for stop in route['stop_sequence']:\n",
    "            if stop in set(swiss_stops_Switzerland_series):\n",
    "                is_in_Switzerland = True\n",
    "                break\n",
    "        if not is_in_Switzerland:\n",
    "            route_id = route['route_id']\n",
    "            non_swiss_routes.add(route_id)\n",
    "    swiss_routes = final_routes.loc[~final_routes['route_id'].isin(non_swiss_routes)]    \n",
    "\n",
    "    return swiss_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''calculates the distances of the trip'''\n",
    "\n",
    "def calculate_distance_from_lat_long(name_first, name_second, stop_df):\n",
    "        lon_first, lat_first = math.radians(stop_df[stop_df['stop_name'] == name_first].iloc[0]['stop_lon']), math.radians(stop_df[stop_df['stop_name'] == name_first].iloc[0]['stop_lat'])\n",
    "        lon_second, lat_second = math.radians(stop_df[stop_df['stop_name'] == name_second].iloc[0]['stop_lon']), math.radians(stop_df[stop_df['stop_name'] == name_second].iloc[0]['stop_lat'])\n",
    "        # The radius of the earth\n",
    "        R = 6373.0 \n",
    "        # To calculate the change in coordinates\n",
    "        dlon = lon_second - lon_first\n",
    "        dlat = lat_second - lat_first\n",
    "        # To use the Haversine formula to get the distance in kilometers between the starting_station and the ending_station\n",
    "        a = math.sin(dlat / 2)**2 + math.cos(lat_first) * math.cos(lat_second) * math.sin(dlon / 2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        # To calculate the distance\n",
    "        distance = R * c\n",
    "        return distance\n",
    "\n",
    "def calculate_distance(stop_sequence, stop_df):\n",
    "    distance = 0\n",
    "    for index_stop ,stop in enumerate(stop_sequence):\n",
    "        index_plus_one = index_stop + 1\n",
    "        if index_plus_one <= len(stop_sequence) - 1:\n",
    "            distance += calculate_distance_from_lat_long(stop, stop_sequence[index_plus_one], stop_df)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 3811889,
     "status": "ok",
     "timestamp": 1616025986893,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "-xK6ZiA9lsX5"
   },
   "outputs": [],
   "source": [
    "'''Makes a set that can be used for building the edges of the graph using Networkx package'''\n",
    "\n",
    "def create_df_for_Networkx(final_routes):\n",
    "    '''return df_for_edges a df that can be used to build a Networkx L-space graph'''\n",
    "    #takes the list stop sequence and make it a new column for each stop\n",
    "    stop_sequence_values = final_routes.apply(lambda x: pd.Series(x['stop_sequence']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    stop_sequence_values.name = 'stop_sequence'\n",
    "    final_routes_stops = final_routes.drop('stop_sequence', axis=1).join(stop_sequence_values)\n",
    "    final_routes_stops = final_routes_stops.reset_index(drop=True)\n",
    "    #Creates a shifted instance of the df to use it for the final result\n",
    "    final_routes_stops_shifted = final_routes_stops.shift()\n",
    "    #Check if which of the rows are followed by a row with the same trip_id\n",
    "    final_routes_stops_shifted['match'] = final_routes_stops_shifted['route_id'].eq(final_routes_stops['route_id'])\n",
    "    #Drop the rows for which this condition is not satisfied\n",
    "    final_routes_stops_shifted.drop(final_routes_stops_shifted[final_routes_stops_shifted['match'] == False].index, inplace = True)\n",
    "    final_routes_stops_shifted.rename(columns=\n",
    "      {\"stop_sequence\": \"stop_name_1\",\n",
    "      \"stop_name\": \"stop_name_1\"}, inplace=True)\n",
    "    #joins the df with its shifted version sothat each sequence of two stations is represented in the table as a row\n",
    "    df_for_edges = final_routes_stops_shifted.join(final_routes_stops[['stop_sequence']], lsuffix='_caller', rsuffix='_other', how='left')\n",
    "    df_for_edges.rename(columns=\n",
    "      {\"stop_sequence\": \"stop_name_2\",\n",
    "      \"stop_name\": \"stop_name_2\"}, inplace=True)\n",
    "\n",
    "    df_for_edges = df_for_edges.drop_duplicates()\n",
    "    df_for_edges = df_for_edges[['route_id','stop_name_1', 'stop_name_2']]\n",
    "    df_for_edges = df_for_edges.reset_index(drop=True)\n",
    "    return df_for_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To apply the route creation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 3812149,
     "status": "ok",
     "timestamp": 1616025987159,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "ZPu3iNo5luB1"
   },
   "outputs": [],
   "source": [
    "def full_route_creation(stop_sequences_df, number_of_trips_per_hash, service_id_count_dates, trips_hash_stop_sequence, stops_cleaned_stop_times_trips_merge_dates, stops_cleaned):\n",
    "    '''return a df that can be used to make a Networkx L-space (with treshold applied of 10%)'''\n",
    "    index_of_extendable, index_of_begin_sequences, index_of_complete_sequences = get_extention_indexes(stop_sequences_df)\n",
    "    route_creation_first = possible_sequences_construction(stop_sequences_df, index_of_extendable, index_of_begin_sequences, index_of_complete_sequences)\n",
    "    route_creation_second = add_full_sequences(stop_sequences_df, route_creation_first, index_of_complete_sequences)\n",
    "    route_creation_third = add_unused_sequences(stop_sequences_df, route_creation_second)\n",
    "    route_creation_frequency_single_travel_time = give_begin_end_time(route_creation_third, trips_hash_stop_sequence, stops_cleaned_stop_times_trips_merge_dates)\n",
    "    route_creation_hash = calculate_hash_route_creation(route_creation_frequency_single_travel_time)\n",
    "    route_hash_freq_combined = regroup_same_stop_sequences(route_creation_hash)\n",
    "    final_routes = apply_treshold_route_creation(route_hash_freq_combined)\n",
    "    swiss_routes = keep_swiss_routes(final_routes)\n",
    "    swiss_routes['distance'] = swiss_routes['stop_sequence'].apply(lambda x: calculate_distance(x, stops_cleaned))\n",
    "    df_for_edges = create_df_for_Networkx(swiss_routes)\n",
    "    \n",
    "    return final_routes, swiss_routes, df_for_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 878
    },
    "executionInfo": {
     "elapsed": 5577932,
     "status": "error",
     "timestamp": 1616027752949,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "vmqiv8rUlzRq",
    "outputId": "e89c814f-6423-4335-97f7-9d10293364cd"
   },
   "outputs": [],
   "source": [
    "#final_routes_Switzerland, swiss_routes_Switzerland, df_for_edges_Switzerland = full_route_creation(route_hash_service_freq_Switzerland, route_hash_service_freq_Switzerland.copy(), service_id_df_Switzerland, trips_hash_stop_sequence_Switzerland, trips_routes_stop_times_stops_dates_Switzerland, stops_cleaned_Switzerland))\n",
    "#final_routes_Switzerland\n",
    "#swiss_routes_Switzerland\n",
    "#df_for_edges_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 5577529,
     "status": "aborted",
     "timestamp": 1616027752553,
     "user": {
      "displayName": "Ine Winters",
      "photoUrl": "",
      "userId": "11267554535649979995"
     },
     "user_tz": -60
    },
    "id": "Mc1yVkXcl6HW"
   },
   "outputs": [],
   "source": [
    "#df_for_edges.to_csv(r'/Users/pol/Desktop/CSV_export/df_for_edges_Switzerland.csv', index = False, header=True, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swiss_routes.to_csv(r'/Users/pol/Desktop/CSV_export/swiss_routes_Switzerland.csv', index = False, header=True, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-fe37d61e3fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroute_creation_second\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_full_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_sequences_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute_creation_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_of_complete_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mroute_creation_third\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_unused_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_sequences_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute_creation_second\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mroute_creation_frequency_single_travel_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgive_begin_end_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroute_creation_third\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrips_hash_stop_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstops_cleaned_stop_times_trips_merge_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mroute_creation_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_hash_route_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroute_creation_frequency_single_travel_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mroute_hash_freq_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregroup_same_stop_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroute_creation_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-eb59932c0462>\u001b[0m in \u001b[0;36mgive_begin_end_time\u001b[0;34m(route_creation_frequency_single, trips_hash_stop_sequence, stops_cleaned_stop_times_trips_merge_dates)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mfull_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstops_cleaned_stop_times_trips_merge_dates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstops_cleaned_stop_times_trips_merge_dates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trip_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_representative_trips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#select) only the last stop sequences of full_times for each trip_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mnew_index_max_per_trip_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'route_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trip_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop_sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mmax_per_trip_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_index_max_per_trip_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#select only the first stop sequences of full_times for each trip_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 \u001b[0;31m# this can be called recursively, so need to raise ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# GH#3688 try to operate item-by-item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stop_sequences_df, number_of_trips_per_hash, service_id_count_dates, trips_hash_stop_sequence, stops_cleaned_stop_times_trips_merge_dates, stops_cleaned = route_hash_service_freq_Switzerland, route_hash_service_freq_Switzerland.copy(), service_id_df_Switzerland, trips_hash_stop_sequence_Switzerland, trips_routes_stop_times_stops_dates_Switzerland, stops_cleaned_Switzerland\n",
    "index_of_extendable, index_of_begin_sequences, index_of_complete_sequences = get_extention_indexes(stop_sequences_df)\n",
    "route_creation_first = possible_sequences_construction(stop_sequences_df, index_of_extendable, index_of_begin_sequences, index_of_complete_sequences)\n",
    "route_creation_second = add_full_sequences(stop_sequences_df, route_creation_first, index_of_complete_sequences)\n",
    "route_creation_third = add_unused_sequences(stop_sequences_df, route_creation_second)\n",
    "route_creation_frequency_single_travel_time = give_begin_end_time(route_creation_third, trips_hash_stop_sequence, stops_cleaned_stop_times_trips_merge_dates)\n",
    "route_creation_hash = calculate_hash_route_creation(route_creation_frequency_single_travel_time)\n",
    "route_hash_freq_combined = regroup_same_stop_sequences(route_creation_hash)\n",
    "final_routes = apply_treshold_route_creation(route_hash_freq_combined)\n",
    "swiss_routes = keep_swiss_routes(final_routes)\n",
    "swiss_routes['distance'] = swiss_routes['stop_sequence'].apply(lambda x: calculate_distance(x, stops_cleaned))\n",
    "df_for_edges = create_df_for_Networkx(swiss_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_sequences_df, number_of_trips_per_hash, service_id_count_dates, trips_hash_stop_sequence, stops_cleaned_stop_times_trips_merge_dates, stops_cleaned = route_hash_service_freq_Switzerland, route_hash_service_freq_Switzerland.copy(), service_id_df_Switzerland, trips_hash_stop_sequence_Switzerland, trips_routes_stop_times_stops_dates_Switzerland, stops_cleaned_Switzerland\n",
    "route_creation_frequency_single_travel_time = give_begin_end_time(route_creation_third, trips_hash_stop_sequence, stops_cleaned_stop_times_trips_merge_dates)\n",
    "route_creation_hash = calculate_hash_route_creation(route_creation_frequency_single_travel_time)\n",
    "route_hash_freq_combined = regroup_same_stop_sequences(route_creation_hash)\n",
    "final_routes = apply_treshold_route_creation(route_hash_freq_combined)\n",
    "swiss_routes = keep_swiss_routes(final_routes)\n",
    "swiss_routes['distance'] = swiss_routes['stop_sequence'].apply(lambda x: calculate_distance(x, stops_cleaned))\n",
    "df_for_edges = create_df_for_Networkx(swiss_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Cleaning_GTFS_Switzerland.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
