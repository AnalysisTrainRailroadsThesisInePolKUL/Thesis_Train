{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To import the required packages.'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "from kneed import KneeLocator\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#import osmnx as ox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To display all output results of a Jupyter cell.'''\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To ensure that the output results of extensive output results are not truncated.'''\n",
    "#pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To change the width of the Notebook to see the output on the screen'''\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Swiss railway system**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of the Swiss railway datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To register the GitHub link with the Swiss data as a variable.'''\n",
    "datalink = \"https://raw.githubusercontent.com/polkuleuven/Thesis_Train/main/gtfs_train_Switzerland_1503/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import all the GTFS data'''\n",
    "#To import the agency dataset that contains limited information about the Swiss SBB railway agency.\n",
    "agency_Switzerland = pd.read_csv(datalink + \"agency.txt\", sep=\",\")\n",
    "#To import the stops dataset that contains information about the ids, the names and the geographical coordinates of the Swiss SBB railway stations.\n",
    "stops_Switzerland = pd.read_csv(datalink + \"stops.txt\", sep=\",\")\n",
    "#To import the feed_info dataset that contains limited information about the Swiss SBB railway feed.\n",
    "feed_info_Switzerland = pd.read_csv(datalink + \"feed_info.txt\", sep=\",\")\n",
    "#To import the transfers dataset that gives the minimum transfer time to switch routes at each Swiss SBB railway station.\n",
    "transfers_not_cleaned_Switzerland = pd.read_csv(datalink + \"transfers.txt\", sep=\",\")\n",
    "#To import the routes dataset that provides the id, the name and the type of vehicle used for all Swiss SBB railway routes.\n",
    "routes_Switzerland = pd.read_csv(datalink + \"routes.txt\", sep=\",\")\n",
    "#To import the trips dataset that gives for all routes an overview of the trips and the headsigns of these trips belonging to the Swiss SBB railway route.\n",
    "#The service_id is an indication of all the dates this trip is valid (consultable in the calendar_dates dataset).\n",
    "trips_Switzerland = pd.read_csv(datalink + \"trips.txt\", sep=\",\")\n",
    "#To import the stop_times dataset that gives for all trips an overview of the ids of the stations served and the sequence in which these stations are served. \n",
    "#In addition, for all the trips the arrival and departure times at the stations served are given.\n",
    "stop_times_Switzerland = pd.read_csv(datalink + \"stop_times.txt\", sep=\",\")\n",
    "#To import the calendar dataset that gives the first and last date of all data observations.\n",
    "calendar_Switzerland = pd.read_csv(datalink + \"calendar.txt\", sep=\",\")\n",
    "#To import the calendar_dates dataset that gives for each service_id all the exact dates when that service_id is valid.\n",
    "calendar_dates_Switzerland = pd.read_csv(datalink + \"calendar_dates.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of the Swiss railway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To clean the routes_Switzerland df'''\n",
    "#To keep the train routes\n",
    "routes_cleaned_Switzerland = routes_Switzerland[routes_Switzerland['route_type'] == 2]\n",
    "routes_cleaned_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To clean the calendar_dates_Switzerland df'''\n",
    "#To filter the dates from the selected begin to the end date\n",
    "begin_date = 20210314\n",
    "end_date = 20210713\n",
    "calendar_dates_cleaned_Switzerland = calendar_dates_Switzerland.copy()\n",
    "calendar_dates_cleaned_Switzerland = calendar_dates_cleaned_Switzerland.drop(calendar_dates_cleaned_Switzerland[(calendar_dates_cleaned_Switzerland['date'] > end_date) |(calendar_dates_cleaned_Switzerland['date'] < begin_date)].index)\n",
    "calendar_dates_cleaned_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To clean the stop_times_Switzerland df'''\n",
    "# To remove the superfluous characters of the stop_id (platform codes)\n",
    "stop_times_cleaned_Switzerland = stop_times_Switzerland.copy()\n",
    "stop_times_cleaned_Switzerland_column = stop_times_cleaned_Switzerland['stop_id'].str.split(':').str[0]\n",
    "stop_times_cleaned_Switzerland.loc[:,'stop_id'] = stop_times_cleaned_Switzerland_column\n",
    "\n",
    "# To make the stop_ids numerical \n",
    "stop_times_cleaned_Switzerland.loc[:,'stop_id'] = stop_times_cleaned_Switzerland.loc[:,'stop_id'].astype(np.int64)\n",
    "stop_times_cleaned_Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To clean the stops_Switzerland df '''\n",
    "#To remove the superfluous characters (platform codes)\n",
    "stops_cleaned_Switzerland_column = stops_Switzerland['stop_id'].str.split(':').str[0]\n",
    "stops_cleaned_Switzerland = stops_Switzerland.copy()\n",
    "stops_cleaned_Switzerland.loc[:,'stop_id'] = stops_cleaned_Switzerland_column\n",
    "\n",
    "#To make the stop_ids numerical and to remove the duplicate stop_ids\n",
    "stops_cleaned_Switzerland = stops_cleaned_Switzerland[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']]\n",
    "stops_cleaned_Switzerland.loc[:,'stop_id'] = stops_cleaned_Switzerland.loc[:,'stop_id'].astype(np.int64)\n",
    "stops_cleaned_Switzerland = stops_cleaned_Switzerland.drop_duplicates()\n",
    "\n",
    "#To remove the accents from the stop_name and to change to uppercase\n",
    "stops_cleaned_Switzerland.loc[:,'stop_name'] = stops_cleaned_Switzerland.loc[:,'stop_name'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "stops_cleaned_Switzerland.loc[:,'stop_name'] = stops_cleaned_Switzerland.loc[:,'stop_name'].str.upper()\n",
    "\n",
    "#To initialize the Nominatim API to get the location from the input string \n",
    "geolocator = Nominatim(user_agent=\"application\")\n",
    "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=0.2)\n",
    "\n",
    "#To get the location with the geolocator.reverse() function and to extract the country from the location instance\n",
    "country_list = []\n",
    "for index, row in stops_cleaned_Switzerland.iterrows():\n",
    "    latitude = row['stop_lat']\n",
    "    longitude = row['stop_lon']\n",
    "    # To assign the latitude and longitude into a geolocator.reverse() method\n",
    "    location = reverse((latitude, longitude), language='en', exactly_one=True)\n",
    "    # To get the country from the given list and parsed into a dictionary with raw function()\n",
    "    address = location.raw['address']\n",
    "    country = address.get('country', '')\n",
    "    country_list.append(country)\n",
    "\n",
    "#To add the values of country_list as a new attribute country     \n",
    "stops_cleaned_Switzerland.loc[:,'country'] = country_list\n",
    "stops_cleaned_Switzerland\n",
    "\n",
    "#To calculate the total number of Belgian stations in the stops_cleaned dataset\n",
    "swiss_stops_Switzerland = stops_cleaned_Switzerland[stops_cleaned_Switzerland['country'] == 'Switzerland']\n",
    "swiss_stops_Switzerland_series = stops_cleaned_Switzerland.loc[stops_cleaned_Switzerland['country'] == 'Switzerland', 'stop_name']\n",
    "#stops_cleaned_Switzerland.to_csv('stops_cleaned_Switzerland.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stops_cleaned_Switzerland = pd.read_csv(\"stops_cleaned_Switzerland.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To merge the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To select all required fields'''\n",
    "agency_cleaned_Switzerland = agency_Switzerland[['agency_id', 'agency_name', 'agency_url', 'agency_timezone']]\n",
    "routes_cleaned_Switzerland = routes_cleaned_Switzerland[['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type']]\n",
    "trips_cleaned_Switzerland = trips_Switzerland[['trip_id', 'route_id', 'service_id', 'trip_headsign']]\n",
    "calendar_dates_cleaned_Switzerland = calendar_dates_cleaned_Switzerland[['service_id', 'date']]\n",
    "stops_cleaned_Switzerland = stops_cleaned_Switzerland[['stop_id', 'stop_name', 'stop_lat', 'stop_lon', 'country']]\n",
    "stop_times_cleaned_Switzerland = stop_times_cleaned_Switzerland[['trip_id', 'stop_id', 'arrival_time', 'departure_time', 'stop_sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' To merge the Swiss files '''\n",
    "#To merge the stop_times df with the stops df on stop_id\n",
    "stop_times_stops_Switzerland = pd.merge(stop_times_cleaned_Switzerland, stops_cleaned_Switzerland[['stop_id','stop_name', 'stop_lat', 'stop_lon', 'country']], on='stop_id')\n",
    "\n",
    "#To merge the trips df with the routes df on route_id\n",
    "routes_trips_Switzerland = pd.merge(routes_cleaned_Switzerland[['route_id']], trips_cleaned_Switzerland, on='route_id')\n",
    "\n",
    "#To merge the stop_times_stops df with the trips_routes df on trip_id\n",
    "routes_trips_stop_times_stops_Switzerland = pd.merge(routes_trips_Switzerland, stop_times_stops_Switzerland, on='trip_id')\n",
    "\n",
    "#To take only the service_ids present in both the routes_trips_stop_times_stops df and the calendar_dates df into account\n",
    "calendar_dates_cleaned_unique_Switzerland = calendar_dates_cleaned_Switzerland['service_id'].unique()\n",
    "routes_trips_stop_times_stops_calendar_dates_Switzerland = routes_trips_stop_times_stops_Switzerland[(routes_trips_stop_times_stops_Switzerland['service_id'].isin(calendar_dates_cleaned_unique_Switzerland))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation space-of-stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verder te gaan met routes_trips_stop_times_stops_calendar_dates_Switzerland of eventueel te hernoemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
